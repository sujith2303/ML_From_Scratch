Parallel computation and each neuron is independent of others
17) neural networks
18) all the notations
19) all the equations
20) back propagation
21) part 2 back prop
22) implementation of nn using python
23) hidden layers in nn
24) deep nn
25) expoding and vanishing gradients
26) why only random initialization
27) implement functions of forward prop
28) implementation of back prop python ( code)
29) softmax activation
30) relu activation
31) bias
32) importance of normalization
33) Batch normalization
34) simple hand written classification
35) what actually a neuron is and Activation vs electric signals