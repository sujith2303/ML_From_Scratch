{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sujithanumala/transformers-from-scratch-pt-summarize-data?scriptVersionId=209955401\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nfrom torch import nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:01:07.847755Z","iopub.execute_input":"2024-11-23T11:01:07.848099Z","iopub.status.idle":"2024-11-23T11:01:10.480851Z","shell.execute_reply.started":"2024-11-23T11:01:07.848069Z","shell.execute_reply":"2024-11-23T11:01:10.479817Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass PositionalEmbeddings(nn.Module):\n    def __init__(self, max_seq_length, embedding_dimension, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.max_seq_length = max_seq_length\n        self.d = embedding_dimension\n        self.pos = torch.arange(0, self.max_seq_length, device=device).unsqueeze(0).unsqueeze(-1)\n        self.i = torch.arange(0, self.d // 2, device=device).unsqueeze(0).unsqueeze(0)\n        # self.pos_embedding = torch.empty(1, self.max_seq_length, self.d, device=device)\n        self.pos_embedding = torch.zeros(1, self.max_seq_length, self.d, device=device)\n        self.pos_embedding[:, :, 0::2] = torch.sin(self.pos / torch.pow(10000, (2 * self.i / self.d)))\n        self.pos_embedding[:, :, 1::2] = torch.cos(self.pos / torch.pow(10000, (2 * self.i / self.d)))\n\n    def forward(self, x):\n        return x + self.pos_embedding\n\nclass EmbeddingLayer(nn.Module):\n    def __init__(self, vocab_size, embedding_dimension, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.embedding = nn.Embedding(vocab_size, embedding_dimension).to(device)\n\n    def forward(self, x):\n        return self.embedding(x.to(self.device))\n\nclass PaddingMask(nn.Module):\n    def __init__(self, device='cpu'):\n        super().__init__()\n        self.device = device\n\n    def forward(self, x):\n        return (x == 0).to(self.device)\n\nclass LookaheadMask(nn.Module):\n    # True to ignore\n    def __init__(self, max_seq_length, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.max_seq_length = max_seq_length\n        # self.mask = torch.tril(torch.ones(self.max_seq_length, self.max_seq_length, device=device))\n\n    # def forward(self):\n    #     return self.mask==0\n    def forward(self):\n        return (torch.tril(torch.ones(self.max_seq_length, self.max_seq_length, device=self.device)) == 0)\n\n\nclass Encoder(nn.Module):\n    def __init__(self, embedding_dim, num_heads, num_dense, dropout_rate=0.1, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.self_attention = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads, batch_first=True, dropout=dropout_rate).to(device)\n        self.dense = nn.Sequential(\n            nn.Linear(embedding_dim, num_dense, bias=True),\n            nn.Dropout(0.1, inplace=False),\n            nn.Linear(num_dense, embedding_dim, bias=True)\n        ).to(device)\n        self.norm1 = nn.LayerNorm(embedding_dim).to(device)\n        self.norm2 = nn.LayerNorm(embedding_dim).to(device)\n\n    def forward(self, x, mask):\n        inp = x\n        x = self.self_attention(x, x, x, need_weights=False, key_padding_mask=mask)[0]\n        x = x + inp\n        x = self.norm1(x)\n        x = x + self.dense(x)\n        x = self.norm2(x)\n        return x\n\nclass Decoder(nn.Module):\n    def __init__(self, embedding_dim, num_heads, num_dense, dropout_rate=0.1, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.masked_mha = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads, batch_first=True, dropout=dropout_rate).to(device)\n        self.mha = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads, batch_first=True, dropout=dropout_rate).to(device)\n        self.dense = nn.Sequential(\n            nn.Linear(embedding_dim, num_dense, bias=True),\n            nn.Dropout(0.1, inplace=False),\n            nn.Linear(num_dense, embedding_dim, bias=True)\n        ).to(device)\n        self.norm1 = nn.LayerNorm(embedding_dim).to(device)\n        self.norm2 = nn.LayerNorm(embedding_dim).to(device)\n        self.norm3 = nn.LayerNorm(embedding_dim).to(device)\n\n    def forward(self, x, enc_mask, enc_inp,dec_padding_mask):\n        inp = x\n        x = self.masked_mha(x, x, x, need_weights=False, attn_mask=dec_padding_mask)[0]\n        x = x + inp\n        x = self.norm1(x)\n        inp = x\n\n        x = self.mha(x, enc_inp, enc_inp, need_weights=False, key_padding_mask=enc_mask,attn_mask = dec_padding_mask)[0]\n        x = x + inp\n        x = self.norm2(x)\n        x = x + self.dense(x)\n        x = self.norm3(x)\n        return x\n\nclass Transformer(nn.Module):\n    def __init__(self, src_vocab_size, tar_vocab_size, embedding_dimension, max_seq_length, num_heads, num_encoder_layers, num_decoder_layers, num_dense, dropout_rate=0.1, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.num_heads = num_heads\n        self.max_seq_len = max_seq_length\n        self.lookahead_mask = LookaheadMask(self.max_seq_len,device  =device)\n        self.emb_src = EmbeddingLayer(src_vocab_size, embedding_dimension, device=device)\n        self.emb_target = EmbeddingLayer(tar_vocab_size, embedding_dimension, device=device)\n        self.pos = PositionalEmbeddings(max_seq_length, embedding_dimension, device=device)\n        self.padding_mask = PaddingMask(device=device)\n        self.encoder_layers = nn.ModuleList([Encoder(embedding_dimension, num_heads, num_dense, dropout_rate, device=device) for _ in range(num_encoder_layers)])\n        self.decoder_layers = nn.ModuleList([Decoder(embedding_dimension, num_heads, num_dense, dropout_rate, device=device) for _ in range(num_decoder_layers)])\n\n    def forward(self, inp_seq, target_seq):\n        inp_seq, target_seq = inp_seq.to(self.device), target_seq.to(self.device)\n        mask = self.padding_mask(inp_seq)\n        x = self.emb_src(inp_seq)\n        x = self.pos(x)\n        for encoder in self.encoder_layers:\n            x = encoder(x, mask)\n            \n        mask_decoder = self.padding_mask(target_seq)\n        target_seq = self.emb_target(target_seq)\n        target_seq = self.pos(target_seq)\n        mask_decoder = ~(~mask_decoder.unsqueeze(1) * ~self.lookahead_mask())\n        # print(mask_decoder.shape)\n        mask_decoder = mask_decoder.repeat(self.num_heads,1,1)\n        # print(mask_decoder.shape)\n        for decoder in self.decoder_layers:\n            x = decoder(target_seq, mask, x,mask_decoder)\n        return x\nclass TransformerSeqSeq(nn.Module):\n    def __init__(self, src_vocab_size=1000, tar_vocab_size=1000, embedding_dimension=300, max_seq_length=512, num_heads=10, num_encoder_layers=3, num_decoder_layers=3, num_dense=1024, dropout_rate=0.1, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.transformer = Transformer(src_vocab_size=src_vocab_size, tar_vocab_size=tar_vocab_size, embedding_dimension=embedding_dimension, max_seq_length=max_seq_length, num_heads=num_heads, num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers, num_dense=num_dense, dropout_rate=dropout_rate, device=device)\n        self.output_layer = nn.Linear(embedding_dimension, tar_vocab_size).to(device)\n\n    def forward(self, inp_seq, target_seq):\n        inp_seq, target_seq = inp_seq.to(self.device), target_seq.to(self.device)\n        transformer_output = self.transformer(inp_seq, target_seq)\n        return self.output_layer(transformer_output)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:05:44.502283Z","iopub.execute_input":"2024-11-23T11:05:44.502599Z","iopub.status.idle":"2024-11-23T11:05:44.526579Z","shell.execute_reply.started":"2024-11-23T11:05:44.50257Z","shell.execute_reply":"2024-11-23T11:05:44.52559Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"class TransformerSeqSeq(nn.Module):\n    def __init__(self, src_vocab_size=1000, tar_vocab_size=1000, embedding_dimension=300, max_seq_length=512, num_heads=10, num_encoder_layers=3, num_decoder_layers=3, num_dense=1024, dropout_rate=0.1, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.transformer = Transformer(src_vocab_size=src_vocab_size, tar_vocab_size=tar_vocab_size, embedding_dimension=embedding_dimension, max_seq_length=max_seq_length, num_heads=num_heads, num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers, num_dense=num_dense, dropout_rate=dropout_rate, device=device)\n        self.output_layer = nn.Linear(embedding_dimension, tar_vocab_size).to(device)\n\n    def forward(self, inp_seq, target_seq):\n        inp_seq, target_seq = inp_seq.to(self.device), target_seq.to(self.device)\n        transformer_output = self.transformer(inp_seq, target_seq)\n        return self.output_layer(transformer_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:05:45.013896Z","iopub.execute_input":"2024-11-23T11:05:45.014598Z","iopub.status.idle":"2024-11-23T11:05:45.020828Z","shell.execute_reply.started":"2024-11-23T11:05:45.014565Z","shell.execute_reply":"2024-11-23T11:05:45.019983Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"# Model Initalization","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = TransformerSeqSeq(src_vocab_size=32100, tar_vocab_size=32100, embedding_dimension=300, max_seq_length=512, num_heads=10, num_encoder_layers=6, num_decoder_layers=6, num_dense=1024, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:05:47.816579Z","iopub.execute_input":"2024-11-23T11:05:47.817341Z","iopub.status.idle":"2024-11-23T11:05:48.301071Z","shell.execute_reply.started":"2024-11-23T11:05:47.817305Z","shell.execute_reply":"2024-11-23T11:05:48.300007Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def count_parameters(model):\n    total = 0\n    trainable =0\n    for name, parameter in model.named_parameters():\n        param = parameter.numel()\n        total+=param\n        if parameter.requires_grad:\n          trainable+=param\n    return f\"Total_parameters: {total}, trainable_parameters: {trainable}, fraction of trainable parameters: {(trainable/total)*100}%\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:05:48.466856Z","iopub.execute_input":"2024-11-23T11:05:48.467747Z","iopub.status.idle":"2024-11-23T11:05:48.472425Z","shell.execute_reply.started":"2024-11-23T11:05:48.46771Z","shell.execute_reply":"2024-11-23T11:05:48.47144Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"count_parameters(model) #42830388","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:05:49.59832Z","iopub.execute_input":"2024-11-23T11:05:49.598658Z","iopub.status.idle":"2024-11-23T11:05:49.605085Z","shell.execute_reply.started":"2024-11-23T11:05:49.598628Z","shell.execute_reply":"2024-11-23T11:05:49.604088Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'Total_parameters: 42830388, trainable_parameters: 42830388, fraction of trainable parameters: 100.0%'"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"# Loading Text Summarization ","metadata":{}},{"cell_type":"code","source":"!pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:01:13.239369Z","iopub.execute_input":"2024-11-23T11:01:13.240063Z","iopub.status.idle":"2024-11-23T11:01:22.674889Z","shell.execute_reply.started":"2024-11-23T11:01:13.240031Z","shell.execute_reply":"2024-11-23T11:01:22.674057Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('prithivMLmods/Context-Based-Chat-Summary-Plus')\n\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:01:22.676582Z","iopub.execute_input":"2024-11-23T11:01:22.67691Z","iopub.status.idle":"2024-11-23T11:01:27.376779Z","shell.execute_reply.started":"2024-11-23T11:01:22.67688Z","shell.execute_reply":"2024-11-23T11:01:27.376008Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/82.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c63bb755648d49349a1d1efd7862bed8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"news_summary_context_plus.csv:   0%|          | 0.00/41.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a27b1ef0f35c444d8befef36bd13c606"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/98401 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d7a940161004008afb6602158f1a75c"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['headlines', 'text'],\n        num_rows: 98401\n    })\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('google-t5/t5-base')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:01:27.377727Z","iopub.execute_input":"2024-11-23T11:01:27.378141Z","iopub.status.idle":"2024-11-23T11:01:29.272073Z","shell.execute_reply.started":"2024-11-23T11:01:27.378113Z","shell.execute_reply":"2024-11-23T11:01:29.271156Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"236ecbf6dbce47dd8e9512a7123c7c06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"460cd72d2a584c0ebe5f089676cb72ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc1b9ce858f4d0da974f1a50a01ef85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1575ab8d92fa468595dcbe526100fb04"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"tokenizer.vocab_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:01:29.274751Z","iopub.execute_input":"2024-11-23T11:01:29.275282Z","iopub.status.idle":"2024-11-23T11:01:29.281267Z","shell.execute_reply.started":"2024-11-23T11:01:29.275233Z","shell.execute_reply":"2024-11-23T11:01:29.280424Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"32100"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def tokenize(example):\n    example['input_ids'] = tokenizer(example['text'],padding = 'max_length',max_length=512,truncation = True)['input_ids']\n    example['labels'] =  tokenizer(example['headlines'],padding = 'max_length',max_length=512,truncation = True)['input_ids']\n    return example","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:01:29.2825Z","iopub.execute_input":"2024-11-23T11:01:29.282813Z","iopub.status.idle":"2024-11-23T11:01:29.291198Z","shell.execute_reply.started":"2024-11-23T11:01:29.282785Z","shell.execute_reply":"2024-11-23T11:01:29.29031Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"ds = dataset['train'].take(50000).map(tokenize)\n# ds = ds.remove_columns(['en','fr'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:01:29.292447Z","iopub.execute_input":"2024-11-23T11:01:29.292734Z","iopub.status.idle":"2024-11-23T11:02:11.362496Z","shell.execute_reply.started":"2024-11-23T11:01:29.292706Z","shell.execute_reply":"2024-11-23T11:02:11.361517Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc95535d7d9d41c89856da7c9fff3b55"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"ds.set_format('torch')\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:02:11.363566Z","iopub.execute_input":"2024-11-23T11:02:11.363824Z","iopub.status.idle":"2024-11-23T11:02:11.370448Z","shell.execute_reply.started":"2024-11-23T11:02:11.363799Z","shell.execute_reply":"2024-11-23T11:02:11.369604Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['headlines', 'text', 'input_ids', 'labels'],\n    num_rows: 50000\n})"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"ds = ds.remove_columns(['headlines','text'])\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:02:11.371403Z","iopub.execute_input":"2024-11-23T11:02:11.371644Z","iopub.status.idle":"2024-11-23T11:02:12.031612Z","shell.execute_reply.started":"2024-11-23T11:02:11.371621Z","shell.execute_reply":"2024-11-23T11:02:12.030699Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'labels'],\n    num_rows: 50000\n})"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ndataloader = DataLoader(ds,batch_size = 16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:02:12.032628Z","iopub.execute_input":"2024-11-23T11:02:12.032983Z","iopub.status.idle":"2024-11-23T11:02:12.037853Z","shell.execute_reply.started":"2024-11-23T11:02:12.032917Z","shell.execute_reply":"2024-11-23T11:02:12.036995Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"tar_vocab_size = tokenizer.vocab_size\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:02:12.041263Z","iopub.execute_input":"2024-11-23T11:02:12.041599Z","iopub.status.idle":"2024-11-23T11:02:12.045757Z","shell.execute_reply.started":"2024-11-23T11:02:12.041572Z","shell.execute_reply":"2024-11-23T11:02:12.044788Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"ds[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:02:12.046905Z","iopub.execute_input":"2024-11-23T11:02:12.04723Z","iopub.status.idle":"2024-11-23T11:02:12.067839Z","shell.execute_reply.started":"2024-11-23T11:02:12.047195Z","shell.execute_reply":"2024-11-23T11:02:12.066866Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([ 7745, 11852,  4540,    17,     6,    46,     3,     9,  5171,    29,\n           302,    13,    95,  4744,    26,    11,  6289,   382,    18,   279,\n            31,     7,     3,  7861,  2350,    16,  5879,  1036,    11, 24714,\n          5869,  2825,  1433,     6,    47,     3,     9,   180,    52,  5479,\n         11597,    44,  7880,     7,    63,     7,    28,   966,   305,   203,\n            13,   161,   351,     5,    37,   478,    11,    95,  4744,    26,\n            31,     7,  9181,    18, 19706,  1415,   380,  2139,   376,  3508,\n            12,     3,     9,  2747, 21166,    44,  7130,  8555,    77,  3515,\n            28, 12669,  9090,  8598,     5,    95,  4744,    26,    31,     7,\n          1777,  2621,  6630,    65, 10028,   220, 27880,  1220, 13325,     5,\n             1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0]),\n 'labels': tensor([   95,  4744,    26,   669,    49, 17490,    12,  1415,    16,     3,\n          6858,     3,   184,   901,    28, 12669,  9090,  8598,     1,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0])}"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"# Training Loop","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(),lr=5e-2)\nloss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:05:58.090607Z","iopub.execute_input":"2024-11-23T11:05:58.090922Z","iopub.status.idle":"2024-11-23T11:05:58.0959Z","shell.execute_reply.started":"2024-11-23T11:05:58.090894Z","shell.execute_reply":"2024-11-23T11:05:58.094869Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"output = model(ds[0:1]['input_ids'],ds[0:1]['labels'])\noutput.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:05:58.66908Z","iopub.execute_input":"2024-11-23T11:05:58.669439Z","iopub.status.idle":"2024-11-23T11:05:58.7166Z","shell.execute_reply.started":"2024-11-23T11:05:58.669409Z","shell.execute_reply":"2024-11-23T11:05:58.715852Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 512, 32100])"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"tokenizer.decode(ds[0]['labels'],skip_special_tokens = True)\ntext = ''\nfor i in range(100):\n    output = model(ds[0:1]['input_ids'],ds[0:1]['labels'])\n    text += tokenizer.decode(torch.argmax())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"(PaddingMask()(ds[0:16]['input_ids']).unsqueeze(1)*LookaheadMask(512)()).shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:02:13.640459Z","iopub.status.idle":"2024-11-23T11:02:13.640908Z","shell.execute_reply.started":"2024-11-23T11:02:13.640674Z","shell.execute_reply":"2024-11-23T11:02:13.640698Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output = model(ds[0:16]['input_ids'].to('cuda'),ds[0:16]['labels'].to('cuda'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:02:13.642853Z","iopub.status.idle":"2024-11-23T11:02:13.643374Z","shell.execute_reply.started":"2024-11-23T11:02:13.643117Z","shell.execute_reply":"2024-11-23T11:02:13.643142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:02:13.644867Z","iopub.status.idle":"2024-11-23T11:02:13.645386Z","shell.execute_reply.started":"2024-11-23T11:02:13.645124Z","shell.execute_reply":"2024-11-23T11:02:13.64515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(tokenizer.decode(ds[100]['labels'],skip_special_tokens = True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:02:13.647115Z","iopub.status.idle":"2024-11-23T11:02:13.647631Z","shell.execute_reply.started":"2024-11-23T11:02:13.647363Z","shell.execute_reply":"2024-11-23T11:02:13.647389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer.decode(tokenizer(text,return_tensors='pt')['input_ids'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:02:13.649037Z","iopub.status.idle":"2024-11-23T11:02:13.649507Z","shell.execute_reply.started":"2024-11-23T11:02:13.649274Z","shell.execute_reply":"2024-11-23T11:02:13.649299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\ntext=''\nrand =  random.randint(0,50000)\nprint(\"Input Text:-\")\nprint(tokenizer.decode(ds[rand]['input_ids'],skip_special_tokens = True))\nfor i in range(50):\n    tar = tokenizer(text,return_tensors='pt',max_length=512,padding='max_length')['input_ids'].to('cuda')\n    output = model(ds[rand:rand+1]['input_ids'].to('cuda'),ds[rand:rand+1]['labels'].to('cuda'))\n    text+=tokenizer.decode(torch.argmax(output[:,-1,:]))+' '\nprint(\"Actual Summary:\",tokenizer.decode(ds[rand]['labels'],skip_special_tokens = True))\nprint()\nprint(\"Generated Summary \\033[95m \",text,'\\033[32m')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:06:24.632976Z","iopub.execute_input":"2024-11-23T11:06:24.633319Z","iopub.status.idle":"2024-11-23T11:06:25.569086Z","shell.execute_reply.started":"2024-11-23T11:06:24.63329Z","shell.execute_reply":"2024-11-23T11:06:25.568205Z"}},"outputs":[{"name":"stdout","text":"Input Text:-\nSpeaking about reservation for women, National Commission for Women Chairperson Rekha Sharma said that it will only help daughters and wives of politicians. She added, \"I've reservations about reservation. It'll be difficult for people like me and you to enter politics with reservation.\" Sharma further said many women who've been elected at panchayat level \"have no clue about their work\".\nActual Summary: Reservation will only help wives of politicians: NCW Head\n\nGenerated Summary \u001b[95m  Luck Luck framed framed Luck Luck framed framed Luck framed Luck framed Luck Luck Luck framed framed Luck framed framed Luck framed Luck Luck framed Luck Luck framed framed Luck framed framed Luck Luck Luck Luck framed framed Luck Luck Luck framed Luck framed Luck Luck framed Luck Luck Luck  \u001b[32m\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"from tqdm import tqdm\nimport random\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    step = 0\n    for i in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n        inp_seq, target_seq  = i['input_ids'],i['labels']\n        inp_seq, target_seq = inp_seq.to(device), target_seq.to(device)\n\n        # Shift the target sequence by one for teacher forcing\n        decoder_input = target_seq  # Keep full length for decoder input\n        target_output = torch.cat([target_seq[:, 1:], torch.zeros((target_seq.size(0), 1), dtype=target_seq.dtype, device=device)], dim=1)\n\n        # Forward pass\n        output = model(inp_seq, decoder_input)\n        output = output.view(-1, tar_vocab_size)\n        target_output = target_output.view(-1)\n\n        # Calculate loss and backpropagate\n        loss = loss_fn(output, target_output)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        if step%100==0:\n            print(f\"Step {step}\")\n            text=''\n            rand =  random.randint(0,50000)\n            print(\"Input Text:-\")\n            print(print(tokenizer.decode(ds[rand]['input_ids'],skip_special_tokens = True)))\n            for i in range(50):\n                tar = tokenizer(text,return_tensors='pt',max_length=512,padding='max_length')['input_ids'].to('cuda')\n                output = model(ds[rand:rand+1]['input_ids'].to('cuda'),ds[rand:rand+1]['labels'].to('cuda'))\n                text+=tokenizer.decode(torch.argmax(output[:,-1,:]))+' '\n            print(\"Actual Summary:\",tokenizer.decode(ds[rand]['labels'],skip_special_tokens = True))\n            print()\n            print(\"Generated Summary \\033[95m \",text,'\\033[32m')\n        step+=1\n    avg_loss = total_loss / len(dataloader)\n    \n    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:06:28.9325Z","iopub.execute_input":"2024-11-23T11:06:28.933084Z","iopub.status.idle":"2024-11-23T11:23:02.705358Z","shell.execute_reply.started":"2024-11-23T11:06:28.933049Z","shell.execute_reply":"2024-11-23T11:23:02.704123Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10:   0%|          | 0/3125 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Step 0\nInput Text:-\nMark Karpeles, former CEO of failed Japan-based Bitcoin exchange Mt. Gox, has said he lost 35 kg in four months in jail as \"lunch was actually two breads with jam\". Karpeles was arrested and jailed in 2015 by police investigating the collapse of Mt. Gox. He said he doesn't want $1-billion that he may receive once bankruptcy proceedings were over.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:   0%|          | 1/3125 [00:01<1:41:53,  1.96s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: Failed Bitcoin exchange CEO lost 35 kgs in prison\n\nGenerated Summary \u001b[95m  </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:   3%|▎         | 100/3125 [01:24<41:39,  1.21it/s]","output_type":"stream"},{"name":"stdout","text":"Step 100\nInput Text:-\nFormer Australian woman cricketer Melissa Quinn faked cancer and used AU$45,000 (â122 lakh) that she raised for her treatment to travel overseas. Former Australian men's cricket team captain Michael Clarke was also involved in the fundraising efforts for her treatment. The police has charged 35-year-old Quinn with fraud offences related to making a financial gain from a fake illness.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:   3%|▎         | 101/3125 [01:25<54:29,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: Aus woman cricketer faked cancer, Michael Clarke gave funds\n\nGenerated Summary \u001b[95m  red red red red red red red red red then red red red red red red red red red red red red red red red red red red red red red red red red red red red red red red red red red red red red red red red red  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:   6%|▋         | 200/3125 [02:44<38:23,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Step 200\nInput Text:-\nA Nigerian professor has been jailed for demanding sex for marks from a student. Richard Akindele was convicted after pleading guilty to four criminal charges, including demanding gratification from a student and sexual coercion of a student. A student had come forward with a recording of Akindele demanding that she either sleep with him or fail the course.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:   6%|▋         | 201/3125 [02:46<50:23,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: Nigerian professor jailed for demanding sex for marks\n\nGenerated Summary \u001b[95m  <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  10%|▉         | 300/3125 [04:04<37:09,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Step 300\nInput Text:-\nRussian football club Spartak Moscow's manager Massimo Carrera dropped captain Denis Glushakov and defender Andrei Eshchenko from the team's first Europa League match of the season for liking an Instagram video criticising him. The video was posted by actor and Spartak supporter Dmitry Nazarov, who mocked Carrera saying he's not \"our happiness\". Spartak lost the match to Rapid Vienna 0-2.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  10%|▉         | 301/3125 [04:06<48:16,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: Coach drops 2 players for liking Instagram video criticising him\n\nGenerated Summary \u001b[95m  <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  13%|█▎        | 400/3125 [05:24<35:50,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Step 400\nInput Text:-\nAfter a 16-year-old girl in Bihar's Gaya was found beheaded, state's weaving community protesting against the murder have sought CBI investigation in the case. The protestors alleged that the Gaya Police is trying to shield the culprits and coerce the victim's parents' confession. While her parents have alleged she was raped by their neighbours, police suspect it was honour killing.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  13%|█▎        | 401/3125 [05:26<46:43,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: Protestors seek CBI probe in Gaya murder, say police saving culprits\n\nGenerated Summary \u001b[95m  <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  16%|█▌        | 500/3125 [06:44<34:31,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Step 500\nInput Text:-\nIn a world filled with predictable formats to success, only a visionary leader creates impact and leaves a mark of greatness. A discerning leader invests a lot of thought behind every decision, including his sartorial choices that help make an impact. Louis Philippe promises to give the finest, most luxuriant products created with superior craftsmanship, truly worthy of a leader.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  16%|█▌        | 501/3125 [06:45<44:50,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: Rise Above The Rest with Louis Philippe\n\nGenerated Summary \u001b[95m  <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  19%|█▉        | 600/3125 [08:03<33:11,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Step 600\nInput Text:-\nThe informal summit between PM Narendra Modi and Chinese President Xi Jinping broke \"new ground\" for Indo-China relations, the Chinese Foreign Ministry has said. The two leaders \"identified the guiding principles for bilateral ties and drew up a blueprint for cooperation\" during the meet. The meet was seen as an improvement in Indo-China ties after the Doklam standoff last year.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  19%|█▉        | 601/3125 [08:05<43:13,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: PM Modi-Xi meet broke new ground for ties with India: China\n\nGenerated Summary \u001b[95m  <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  22%|██▏       | 700/3125 [09:23<31:55,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Step 700\nInput Text:-\nInitial data analysis of Ultima Thule, the farthest cosmic object ever explored, by New Horizons spacecraft has found no signs of an atmosphere yet, NASA said. No evidence of rings or satellites larger than one mile in diameter orbiting the object was found, NASA added. New Horizons had studied the object from a distance of around 3,500 kilometres.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  22%|██▏       | 701/3125 [09:25<41:29,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: No signs of atmosphere yet on farthest explored object: NASA\n\nGenerated Summary \u001b[95m  <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  26%|██▌       | 800/3125 [10:43<30:37,  1.26it/s]","output_type":"stream"},{"name":"stdout","text":"Step 800\nInput Text:-\nA passenger has claimed that he suffered food poisoning on December 18 after eating a muffin he purchased from a shop at Delhi's IGI airport, in which he found parts of a dead lizard. The passenger had to be rushed to the hospital after he started vomiting, airport officials said. The police sent the food sample to the forensic lab.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  26%|██▌       | 801/3125 [10:44<39:50,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: Man claims finding dead lizard in muffin bought from Delhi airport\n\nGenerated Summary \u001b[95m  <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  29%|██▉       | 900/3125 [12:03<29:15,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Step 900\nInput Text:-\nChennai-based costume designer Pallavi Singh has claimed her Uber cab burnt to ashes on a flyover on Saturday night. \"I saw smoke coming from the foot area and possibly AC ducts...The driver hadn't spotted it or taken any action,\" said Singh. She and the driver left the car after other people informed them of sparks coming out from the car.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  29%|██▉       | 901/3125 [12:04<38:02,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: Woman claims her Uber cab burnt to ashes in Chennai, shares video\n\nGenerated Summary \u001b[95m  <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  32%|███▏      | 1000/3125 [13:22<27:55,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1000\nInput Text:-\nIranian President Hassan Rouhani on Friday questioned why India with a population of over 1 billion does not have veto power at the UN Security Council (UNSC) while the US does. He further said that giving veto rights only to the five nuclear powers at the time of the UNSC's formation was unfair.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  32%|███▏      | 1001/3125 [13:24<36:18,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: Why does US have veto rights and not India, asks Iran\n\nGenerated Summary \u001b[95m  <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  35%|███▌      | 1100/3125 [14:42<26:36,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1100\nInput Text:-\nLate actor Vinod Khanna's first wife Geetanjali Khanna, mother of actors Akshaye Khanna and Rahul Khanna passed away at the age of 70 on Saturday. Although the exact cause of the death is yet to be known, Geetanjali was reportedly already suffering from a heart ailment. Her funeral took place earlier today.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  35%|███▌      | 1101/3125 [14:44<34:35,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: Late actor Vinod Khanna's 1st wife Geetanjali passes away\n\nGenerated Summary \u001b[95m  <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  38%|███▊      | 1200/3125 [16:02<25:19,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1200\nInput Text:-\nAfter exiting the ruling NDA alliance, TDP chief and Andhra Pradesh CM Chandrababu Naidu met several Opposition leaders during his two-day visit to Delhi to muster support for the state's special status demand. Naidu met NCP President Sharad Pawar, former Jammu and Kashmir CM Farooq Abdullah, TMC MP Derek O'Brien and Delhi CM Arvind Kejriwal among others.\nNone\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  38%|███▊      | 1201/3125 [16:03<32:56,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Actual Summary: Andhra CM meets Opp'n leaders in Delhi over special status\n\nGenerated Summary \u001b[95m  <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>  \u001b[32m\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10:  40%|███▉      | 1238/3125 [16:33<25:14,  1.25it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 25\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":34},{"cell_type":"code","source":"target = torch.cat((torch.ones(1,1,dtype = inp.dtype),torch.zeros(1,9,dtype = inp.dtype)),dim=-1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text = \" \"\nfor i in range(10):\n    target = tokenizer(text,return_tensors='pt',max_length = 50,padding=  \"max_length\")['input_ids']\n    # tokenizer.decode(inp_seq[0,:],skip_special_tokens = True),tokenizer.decode(target_seq[0,:],skip_special_tokens = True)\n    outputs = model(inp,target)\n    text+=tokenizer.decode(torch.argmax(outputs[0,-1,:],dim=-1))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Using Inbuilt nn.Transformers","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class trans(nn.Module):\n    def __init__(self):\n        super().__init__()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Working model using nn.transformer","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom datasets import load_dataset\nfrom torch.utils.data import DataLoader\nimport random\nfrom tqdm import tqdm\nimport math","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_parameters(model):\n    total = 0\n    trainable =0\n    for name, parameter in model.named_parameters():\n        param = parameter.numel()\n        total+=param\n        if parameter.requires_grad:\n          trainable+=param\n    return f\"Total_parameters: {total}, trainable_parameters: {trainable}, fraction of trainable parameters: {(trainable/total)*100}%\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:24:18.315371Z","iopub.execute_input":"2024-11-27T15:24:18.31619Z","iopub.status.idle":"2024-11-27T15:24:18.320738Z","shell.execute_reply.started":"2024-11-27T15:24:18.316154Z","shell.execute_reply":"2024-11-27T15:24:18.319789Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class PaddingMask(nn.Module):\n    def __init__(self, device='cpu'):\n        super().__init__()\n        self.device = device\n\n    def forward(self, x):\n        return (x == 0).to(self.device)\n\nclass LookaheadMask(nn.Module):\n    # True to ignore\n    def __init__(self, device='cpu'):\n        super().__init__()\n        self.device = device\n\n    def forward(self,tgt):\n        tgt_seq_length = tgt.size(1)\n        tgt_pad_mask = PaddingMask(self.device)(tgt).unsqueeze(1)\n        tgt_causal_mask = torch.triu(torch.ones(\n            tgt_seq_length, tgt_seq_length, device=tgt.device\n        )).bool()\n        tgt_mask = ~tgt_pad_mask & tgt_causal_mask\n        return ~tgt_mask.to(self.device)\n\nclass PositionalEmbeddings(nn.Module):\n    def __init__(self, max_seq_length, embedding_dimension, device='cpu'):\n        super().__init__()\n        self.device = device\n        self.max_seq_length = max_seq_length\n        self.d = embedding_dimension\n        self.pos = torch.arange(0, self.max_seq_length, device=device).unsqueeze(0).unsqueeze(-1)\n        self.i = torch.arange(0, self.d // 2, device=device).unsqueeze(0).unsqueeze(0)\n        self.pos_embedding = torch.empty(1, self.max_seq_length, self.d, device=device)\n        self.pos_embedding[:, :, 0::2] = torch.sin(self.pos / torch.pow(10000, (2 * self.i / self.d)))\n        self.pos_embedding[:, :, 1::2] = torch.cos(self.pos / torch.pow(10000, (2 * self.i / self.d)))\n\n    def forward(self, x):\n        return x + self.pos_embedding[:, :x.size(1), :].to(self.device)\n\n\nclass TransformerSeqSeq(nn.Module):\n    def __init__(self,\n                 src_vocab_size=1000,\n                 tar_vocab_size=1000,\n                 embedding_dimension=300,\n                 max_seq_length=512,\n                 num_heads=10,\n                 num_encoder_layers=3,\n                 num_decoder_layers=3,\n                 num_dense=1024,\n                 dropout_rate=0.1,\n                 device='cpu'):\n        super().__init__()\n        self.embedding_dimension = embedding_dimension\n        self.src_embedding = nn.Embedding(src_vocab_size, embedding_dimension,device = device)\n        self.tar_embedding = nn.Embedding(tar_vocab_size, embedding_dimension,device = device)\n        self.padding_mask_src = PaddingMask(device = device)\n        self.pos = PositionalEmbeddings(max_seq_length, embedding_dimension,device = device)\n        self.lookaheadmask = LookaheadMask(device= device)\n        self.transformer = nn.Transformer(d_model=embedding_dimension,\n                                          nhead=num_heads,\n                                          batch_first = True,\n                                          num_encoder_layers=num_encoder_layers,\n                                          num_decoder_layers=num_decoder_layers,\n                                          dim_feedforward=num_dense,\n                                          dropout=dropout_rate,\n                                          device=device)\n        self.linear = nn.Linear(embedding_dimension, tar_vocab_size,device=device)\n\n    def forward(self, inp_seq, target_seq):\n        src = self.src_embedding(inp_seq) * math.sqrt(self.embedding_dimension)\n        tgt = self.tar_embedding(target_seq) * math.sqrt(self.embedding_dimension)\n        src = self.pos(src)\n        tgt = self.pos(tgt)\n        src_key_padding_mask =  self.padding_mask_src(inp_seq)\n        # tgt_key_padding_mask = self.padding_mask_src(target_seq)\n        tgt_mask = self.lookaheadmask(target_seq)\n\n        x = self.transformer(src = src,\n                         tgt = tgt,\n                         src_key_padding_mask = src_key_padding_mask,\n                         tgt_mask = tgt_mask,\n                         memory_key_padding_mask = src_key_padding_mask,\n                         tgt_is_causal = True\n                          )\n\n        return self.linear(x)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:45:48.177607Z","iopub.execute_input":"2024-11-27T15:45:48.178356Z","iopub.status.idle":"2024-11-27T15:45:48.192706Z","shell.execute_reply.started":"2024-11-27T15:45:48.178324Z","shell.execute_reply":"2024-11-27T15:45:48.191876Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"max_seq_len = 100\ntgt_max_seq_len = 50\nsrc_vocab_size=32100\ntar_vocab_size=32100\nembedding_dimension=512\nnum_heads=10\nnum_encoder_layers=3\nnum_decoder_layers=3\nnum_dense=512\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbatch_size = 32\nlr = 1e-4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:45:49.762738Z","iopub.execute_input":"2024-11-27T15:45:49.763159Z","iopub.status.idle":"2024-11-27T15:45:49.768931Z","shell.execute_reply.started":"2024-11-27T15:45:49.76312Z","shell.execute_reply":"2024-11-27T15:45:49.767904Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"transformer = TransformerSeqSeq(\n                        src_vocab_size=src_vocab_size,\n                        tar_vocab_size=tar_vocab_size,\n                        embedding_dimension=embedding_dimension,\n                        max_seq_length=max_seq_len,\n                        num_heads=num_heads,\n                        num_encoder_layers=num_encoder_layers,\n                        num_decoder_layers=num_decoder_layers,\n                        num_dense=num_dense,\n                        device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:45:50.136511Z","iopub.execute_input":"2024-11-27T15:45:50.136959Z","iopub.status.idle":"2024-11-27T15:45:50.16413Z","shell.execute_reply.started":"2024-11-27T15:45:50.136919Z","shell.execute_reply":"2024-11-27T15:45:50.163148Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"for p in transformer.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:45:51.105127Z","iopub.execute_input":"2024-11-27T15:45:51.10549Z","iopub.status.idle":"2024-11-27T15:45:51.1121Z","shell.execute_reply.started":"2024-11-27T15:45:51.105455Z","shell.execute_reply":"2024-11-27T15:45:51.111329Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"count_parameters(transformer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:45:51.696504Z","iopub.execute_input":"2024-11-27T15:45:51.697203Z","iopub.status.idle":"2024-11-27T15:45:51.70253Z","shell.execute_reply.started":"2024-11-27T15:45:51.697171Z","shell.execute_reply":"2024-11-27T15:45:51.70184Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"'Total_parameters: 34031172, trainable_parameters: 34031172, fraction of trainable parameters: 100.0%'"},"metadata":{}}],"execution_count":77},{"cell_type":"markdown","source":"# Creating data","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset('prithivMLmods/Context-Based-Chat-Summary-Plus')\n\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:26:43.295447Z","iopub.execute_input":"2024-11-27T15:26:43.295814Z","iopub.status.idle":"2024-11-27T15:26:46.584112Z","shell.execute_reply.started":"2024-11-27T15:26:43.295785Z","shell.execute_reply":"2024-11-27T15:26:46.583386Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/82.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74ff83e732fd4cbd83934e631e5cb65b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"news_summary_context_plus.csv:   0%|          | 0.00/41.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"146145da3dcd4990878146c8607ee406"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/98401 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48d47ff3d650489099293b908a478be1"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['headlines', 'text'],\n        num_rows: 98401\n    })\n})"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('google-t5/t5-base')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:26:52.858751Z","iopub.execute_input":"2024-11-27T15:26:52.859077Z","iopub.status.idle":"2024-11-27T15:26:55.292624Z","shell.execute_reply.started":"2024-11-27T15:26:52.85905Z","shell.execute_reply":"2024-11-27T15:26:55.291717Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa065213410046fa8b9704b0656d5256"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed4e099074e54f3ab10aab11f3d05cee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e895b3dc8fcc468f89cfe37cba0b9ed9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc7663e9ae2c45ba8155f2c6f0269ed4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"tokenizer(\"<unk> hello\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:39:49.988061Z","iopub.execute_input":"2024-11-27T15:39:49.988391Z","iopub.status.idle":"2024-11-27T15:39:49.995157Z","shell.execute_reply.started":"2024-11-27T15:39:49.988363Z","shell.execute_reply":"2024-11-27T15:39:49.994264Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [2, 21820, 1], 'attention_mask': [1, 1, 1]}"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"def tokenize(example):\n    example['input_ids'] = tokenizer(example['text'],padding = 'max_length',max_length=max_seq_len,truncation = True)['input_ids']\n    example['labels'] =  tokenizer('<unk>'+example['headlines'],padding = 'max_length',max_length=tgt_max_seq_len,truncation = True)['input_ids']\n    return example","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:40:00.031273Z","iopub.execute_input":"2024-11-27T15:40:00.031612Z","iopub.status.idle":"2024-11-27T15:40:00.036927Z","shell.execute_reply.started":"2024-11-27T15:40:00.031584Z","shell.execute_reply":"2024-11-27T15:40:00.035824Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"ds = dataset['train'].map(tokenize)\nds.set_format('torch')\nds = ds.remove_columns(['headlines','text'])\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T16:08:03.811894Z","iopub.execute_input":"2024-11-27T16:08:03.812848Z","iopub.status.idle":"2024-11-27T16:09:03.06094Z","shell.execute_reply.started":"2024-11-27T16:08:03.812803Z","shell.execute_reply":"2024-11-27T16:09:03.060083Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/98401 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f48ad7c991a84cd089b50b0f7ccc0780"}},"metadata":{}},{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'labels'],\n    num_rows: 98401\n})"},"metadata":{}}],"execution_count":138},{"cell_type":"code","source":"ds[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:40:01.41959Z","iopub.execute_input":"2024-11-27T15:40:01.419866Z","iopub.status.idle":"2024-11-27T15:40:01.428974Z","shell.execute_reply.started":"2024-11-27T15:40:01.419839Z","shell.execute_reply":"2024-11-27T15:40:01.427976Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([ 7745, 11852,  4540,    17,     6,    46,     3,     9,  5171,    29,\n           302,    13,    95,  4744,    26,    11,  6289,   382,    18,   279,\n            31,     7,     3,  7861,  2350,    16,  5879,  1036,    11, 24714,\n          5869,  2825,  1433,     6,    47,     3,     9,   180,    52,  5479,\n         11597,    44,  7880,     7,    63,     7,    28,   966,   305,   203,\n            13,   161,   351,     5,    37,   478,    11,    95,  4744,    26,\n            31,     7,  9181,    18, 19706,  1415,   380,  2139,   376,  3508,\n            12,     3,     9,  2747, 21166,    44,  7130,  8555,    77,  3515,\n            28, 12669,  9090,  8598,     5,    95,  4744,    26,    31,     7,\n          1777,  2621,  6630,    65, 10028,   220, 27880,  1220, 13325,     1]),\n 'labels': tensor([    2,    95,  4744,    26,   669,    49, 17490,    12,  1415,    16,\n             3,  6858,     3,   184,   901,    28, 12669,  9090,  8598,     1,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0])}"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"dataloader = DataLoader(ds,batch_size = batch_size,shuffle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T16:09:03.087287Z","iopub.execute_input":"2024-11-27T16:09:03.087601Z","iopub.status.idle":"2024-11-27T16:09:03.092394Z","shell.execute_reply.started":"2024-11-27T16:09:03.087563Z","shell.execute_reply":"2024-11-27T16:09:03.09161Z"}},"outputs":[],"execution_count":139},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"transformer.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(ignore_index=0)\noptimizer = torch.optim.Adam(transformer.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\ntransformer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformer(ds['input_ids'][0:1,:].to(device),ds['labels'][0:1,:-1].to(device))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T15:51:03.313905Z","iopub.execute_input":"2024-11-27T15:51:03.314245Z","iopub.status.idle":"2024-11-27T15:51:03.33928Z","shell.execute_reply.started":"2024-11-27T15:51:03.31421Z","shell.execute_reply":"2024-11-27T15:51:03.338189Z"}},"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"tensor([[[-0.0082,  0.1415,  0.0273,  ...,  0.1750,  0.0555,  0.1956],\n         [-0.0624, -0.0183,  0.1365,  ...,  0.0470, -0.0080,  0.1138],\n         [-0.1381,  0.1086, -0.0697,  ...,  0.1529, -0.0009,  0.1477],\n         ...,\n         [ 0.0457,  0.2001,  0.0626,  ...,  0.2272,  0.1193,  0.1319],\n         [ 0.0878,  0.3418,  0.0517,  ...,  0.1796,  0.0950,  0.1049],\n         [-0.0080,  0.2503,  0.1252,  ...,  0.1035,  0.0275,  0.1878]]],\n       device='cuda:0', grad_fn=<ViewBackward0>)"},"metadata":{}}],"execution_count":94},{"cell_type":"code","source":"batch_size = 256","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T16:00:02.001487Z","iopub.execute_input":"2024-11-27T16:00:02.002175Z","iopub.status.idle":"2024-11-27T16:00:02.00615Z","shell.execute_reply.started":"2024-11-27T16:00:02.002142Z","shell.execute_reply":"2024-11-27T16:00:02.005248Z"}},"outputs":[],"execution_count":129},{"cell_type":"code","source":"from tqdm import tqdm\nfor epoch in tqdm(range(10)):\n    total_loss = 0\n    steps = 0\n    for batch in dataloader:\n        src_data,tgt_data = batch['input_ids'],batch['labels']\n        optimizer.zero_grad()\n        output = transformer(src_data.to(device), tgt_data[:, :-1].to(device))\n        loss = criterion(output.contiguous().view(-1, tar_vocab_size), tgt_data[:, 1:].contiguous().view(-1).to(device))\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(transformer.parameters(), max_norm=1.0)\n        optimizer.step()\n        total_loss+=loss.item()\n        if steps%100==0:\n            print(f\"Epoch: {epoch+1} Step:{steps}, Loss: {loss.item()}\")\n        steps+=1\n    total_loss = total_loss/(1000//batch_size)\n    print(f\"Epoch: {epoch+1}, Loss: {total_loss}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:06:43.969308Z","iopub.execute_input":"2024-11-27T17:06:43.969649Z","iopub.status.idle":"2024-11-27T17:29:48.189612Z","shell.execute_reply.started":"2024-11-27T17:06:43.969619Z","shell.execute_reply":"2024-11-27T17:29:48.188501Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1 Step:0, Loss: 2.2565841674804688\nEpoch: 1 Step:100, Loss: 2.2183072566986084\nEpoch: 1 Step:200, Loss: 2.2576961517333984\nEpoch: 1 Step:300, Loss: 2.247067451477051\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [04:39<41:52, 279.19s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Loss: 293.23545654614765\nEpoch: 2 Step:0, Loss: 2.1719088554382324\nEpoch: 2 Step:100, Loss: 2.075241804122925\nEpoch: 2 Step:200, Loss: 2.1345324516296387\nEpoch: 2 Step:300, Loss: 2.177013397216797\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [09:18<37:16, 279.53s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Loss: 275.4828146298726\nEpoch: 3 Step:0, Loss: 1.9606125354766846\nEpoch: 3 Step:100, Loss: 1.9886444807052612\nEpoch: 3 Step:200, Loss: 2.0135953426361084\nEpoch: 3 Step:300, Loss: 2.0636227130889893\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [13:58<32:37, 279.63s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Loss: 258.6726336479187\nEpoch: 4 Step:0, Loss: 1.8781142234802246\nEpoch: 4 Step:100, Loss: 1.8057607412338257\nEpoch: 4 Step:200, Loss: 1.790067195892334\nEpoch: 4 Step:300, Loss: 1.8514528274536133\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [18:38<27:58, 279.76s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Loss: 243.0717405875524\nEpoch: 5 Step:0, Loss: 1.6899030208587646\nEpoch: 5 Step:100, Loss: 1.8466196060180664\nEpoch: 5 Step:200, Loss: 1.817838191986084\nEpoch: 5 Step:300, Loss: 1.7945115566253662\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [23:04<34:36, 346.04s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[169], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(transformer\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 13\u001b[0m total_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m steps\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":169},{"cell_type":"code","source":"text = \"\"\"As per a report in Times of India, \"Gill is likely to miss the two-day practice match at Canberra, which will start from Saturday.\"\n\nThe second Test will begin in Adelaide from December 6.\n\n\"Gill was advised a 10-14 day rest by the medical specialist after suffering that injury. He won't play in the practice match on the weekend, and is doubtful at the moment for the second Test too. Let's see how much his injury has healed, how his finger feels. Even after it has healed, he'll need some quality practice before playing a Test match,\" a source tracking developments told TOI.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:43:51.652023Z","iopub.execute_input":"2024-11-27T17:43:51.652807Z","iopub.status.idle":"2024-11-27T17:43:51.656723Z","shell.execute_reply.started":"2024-11-27T17:43:51.652774Z","shell.execute_reply":"2024-11-27T17:43:51.655801Z"}},"outputs":[],"execution_count":196},{"cell_type":"code","source":"result = torch.tensor([2],dtype=int,device = device).unsqueeze(0)\nsrc_data = tokenizer(text,return_tensors = 'pt',padding = 'max_length',max_length = 100,truncation = True)['input_ids']\nfor i in range(50):\n  output = transformer(src_data.to(device),result)[:,i,:]\n  result = torch.cat((result, torch.argmax(output,dim=-1).unsqueeze(0)),dim =  -1)\nresult","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:43:51.866537Z","iopub.execute_input":"2024-11-27T17:43:51.867155Z","iopub.status.idle":"2024-11-27T17:43:52.253698Z","shell.execute_reply.started":"2024-11-27T17:43:51.867123Z","shell.execute_reply":"2024-11-27T17:43:52.25292Z"}},"outputs":[{"execution_count":197,"output_type":"execute_result","data":{"text/plain":"tensor([[    2,  1547,    12,  3041,   204,   517,   227,   204,   517, 12025,\n             7,     6,  3041,    91,     3,    31,   517,     9,  1135,     1,\n            31,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1]], device='cuda:0')"},"metadata":{}}],"execution_count":197},{"cell_type":"code","source":"tokenizer.decode(src_data[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:43:54.21203Z","iopub.execute_input":"2024-11-27T17:43:54.212367Z","iopub.status.idle":"2024-11-27T17:43:54.218951Z","shell.execute_reply.started":"2024-11-27T17:43:54.212338Z","shell.execute_reply":"2024-11-27T17:43:54.217948Z"}},"outputs":[{"execution_count":198,"output_type":"execute_result","data":{"text/plain":"'As per a report in Times of India, \"Gill is likely to miss the two-day practice match at Canberra, which will start from Saturday.\" The second Test will begin in Adelaide from December 6. \"Gill was advised a 10-14 day rest by the medical specialist after suffering that injury. He won\\'t play in the practice match on the weekend, and is doubtful at the moment for the second Test too. Let\\'s see how much his injury has healed,</s>'"},"metadata":{}}],"execution_count":198},{"cell_type":"code","source":"tokenizer.decode(result[0],skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T17:43:55.132628Z","iopub.execute_input":"2024-11-27T17:43:55.133038Z","iopub.status.idle":"2024-11-27T17:43:55.139503Z","shell.execute_reply.started":"2024-11-27T17:43:55.133006Z","shell.execute_reply":"2024-11-27T17:43:55.138648Z"}},"outputs":[{"execution_count":199,"output_type":"execute_result","data":{"text/plain":"\"India to miss 2G after 2G squads, miss out 'Gaday'\""},"metadata":{}}],"execution_count":199},{"cell_type":"code","source":"for epoch in range(500):\n  total_loss = 0\n  for i in range(1000//batch_size):\n    optimizer.zero_grad()\n    output = transformer(src_data[i*batch_size:i*batch_size+batch_size], tgt_data[i*batch_size:i*batch_size+batch_size, :-1])\n    loss = criterion(output.contiguous().view(-1, tar_vocab_size), tgt_data[i*batch_size:i*batch_size+batch_size, 1:].contiguous().view(-1))\n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(transformer.parameters(), max_norm=1.0)\n    optimizer.step()\n    total_loss+=loss.item()\n  total_loss = total_loss/(1000//batch_size)\n  print(f\"Epoch: {epoch+1}, Loss: {total_loss}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}