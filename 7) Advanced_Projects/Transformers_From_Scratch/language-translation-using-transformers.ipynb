{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1067156,"sourceType":"datasetVersion","datasetId":592212}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Without Hugging Face Transformers","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport collections\nimport os\nimport re\nimport keras.backend as K\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:15:10.182752Z","iopub.execute_input":"2023-11-16T08:15:10.183780Z","iopub.status.idle":"2023-11-16T08:15:10.189788Z","shell.execute_reply.started":"2023-11-16T08:15:10.183745Z","shell.execute_reply":"2023-11-16T08:15:10.188760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('/kaggle/input/language-translation-englishfrench')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:15:10.650936Z","iopub.execute_input":"2023-11-16T08:15:10.651345Z","iopub.status.idle":"2023-11-16T08:15:10.664720Z","shell.execute_reply.started":"2023-11-16T08:15:10.651317Z","shell.execute_reply":"2023-11-16T08:15:10.663883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !wget http://nlp.stanford.edu/data/glove.6B.zip\n# !unzip -q glove.6B.zip","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:48:34.259091Z","iopub.execute_input":"2023-11-11T12:48:34.259451Z","iopub.status.idle":"2023-11-11T12:48:34.264087Z","shell.execute_reply.started":"2023-11-11T12:48:34.259424Z","shell.execute_reply":"2023-11-11T12:48:34.262989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/language-translation-englishfrench/eng_-french.csv\")\ndf[\"French words/sentences\"]=(\"<SOS> \"+df[\"French words/sentences\"]+\" <EOS>\")\ndf[\"English words/sentences\"]=(\"<SOS> \"+df[\"English words/sentences\"]+\" <EOS>\")\ndf=df.sample(frac=1).reset_index(drop=True)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:16:05.539609Z","iopub.execute_input":"2023-11-16T08:16:05.539978Z","iopub.status.idle":"2023-11-16T08:16:06.058132Z","shell.execute_reply.started":"2023-11-16T08:16:05.539948Z","shell.execute_reply":"2023-11-16T08:16:06.057179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"French word numbers\"]=(df['English words/sentences'].str.split().apply(len))\ndf[\"English word numbers\"]=(df['French words/sentences'].str.split().apply(len))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:16:12.970351Z","iopub.execute_input":"2023-11-16T08:16:12.971230Z","iopub.status.idle":"2023-11-16T08:16:14.458827Z","shell.execute_reply.started":"2023-11-16T08:16:12.971187Z","shell.execute_reply":"2023-11-16T08:16:14.457772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:16:19.522945Z","iopub.execute_input":"2023-11-16T08:16:19.523797Z","iopub.status.idle":"2023-11-16T08:16:19.535790Z","shell.execute_reply.started":"2023-11-16T08:16:19.523754Z","shell.execute_reply":"2023-11-16T08:16:19.534668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_to_plot = df[[\"French word numbers\", \"English word numbers\"]]\nsns.boxplot(data=data_to_plot)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:49:57.144883Z","iopub.execute_input":"2023-11-11T12:49:57.145305Z","iopub.status.idle":"2023-11-11T12:49:57.523887Z","shell.execute_reply.started":"2023-11-11T12:49:57.145278Z","shell.execute_reply":"2023-11-11T12:49:57.522811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.hist(data_to_plot, bins=15, alpha=1)\nplt.xlim(0, 40)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:50:01.351984Z","iopub.execute_input":"2023-11-11T12:50:01.352855Z","iopub.status.idle":"2023-11-11T12:50:01.820134Z","shell.execute_reply.started":"2023-11-11T12:50:01.352820Z","shell.execute_reply":"2023-11-11T12:50:01.819183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eng = df['English words/sentences']\nfr = df['French words/sentences']","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:16:29.862129Z","iopub.execute_input":"2023-11-16T08:16:29.862521Z","iopub.status.idle":"2023-11-16T08:16:29.867224Z","shell.execute_reply.started":"2023-11-16T08:16:29.862493Z","shell.execute_reply":"2023-11-16T08:16:29.866092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"english_words_counter = collections.Counter([word for sentence in eng for word in sentence.split()])\nfrench_words_counter = collections.Counter([word for sentence in fr for word in sentence.split()])\n\nprint('{} English words.'.format(len([word for sentence in eng for word in sentence.split()])))\nprint('{} unique English words.'.format(len(english_words_counter)))\nprint('10 Most common words in the English dataset:')\nprint('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\nprint()\nprint('{} French words.'.format(len([word for sentence in fr for word in sentence.split()])))\nprint('{} unique French words.'.format(len(french_words_counter)))\nprint('10 Most common words in the French dataset:')\nprint('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:50:04.838130Z","iopub.execute_input":"2023-11-11T12:50:04.838472Z","iopub.status.idle":"2023-11-11T12:50:06.208764Z","shell.execute_reply.started":"2023-11-11T12:50:04.838443Z","shell.execute_reply":"2023-11-11T12:50:06.207848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(x):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(x)\n    return tokenizer.texts_to_sequences(x), tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:16:44.070750Z","iopub.execute_input":"2023-11-16T08:16:44.071715Z","iopub.status.idle":"2023-11-16T08:16:44.076127Z","shell.execute_reply.started":"2023-11-16T08:16:44.071679Z","shell.execute_reply":"2023-11-16T08:16:44.075145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pad(x, length=14):\n    if length is None:\n        length = max([len(sentence) for sentence in x])\n    return pad_sequences(x, maxlen = length, padding = 'post')","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:16:45.612921Z","iopub.execute_input":"2023-11-16T08:16:45.613545Z","iopub.status.idle":"2023-11-16T08:16:45.618716Z","shell.execute_reply.started":"2023-11-16T08:16:45.613512Z","shell.execute_reply":"2023-11-16T08:16:45.617746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    cleaned_texts=[]\n    for sent in text:\n        cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', sent)\n        cleaned_texts.append(cleaned_text)\n    return cleaned_texts","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:17:06.362046Z","iopub.execute_input":"2023-11-16T08:17:06.362413Z","iopub.status.idle":"2023-11-16T08:17:06.367680Z","shell.execute_reply.started":"2023-11-16T08:17:06.362383Z","shell.execute_reply":"2023-11-16T08:17:06.366675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(x, y):\n#     cleaned_x=remove_stop(x,\"english\")\n#     cleaned_y=remove_stop(y,\"french\")\n\n    preprocess_x, x_tk = tokenize(x)\n    preprocess_y, y_tk = tokenize(y)\n\n    preprocess_x = pad(preprocess_x)\n    preprocess_y = pad(preprocess_y)\n\n    return preprocess_x, preprocess_y, x_tk, y_tk","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:17:16.151022Z","iopub.execute_input":"2023-11-16T08:17:16.151606Z","iopub.status.idle":"2023-11-16T08:17:16.156588Z","shell.execute_reply.started":"2023-11-16T08:17:16.151572Z","shell.execute_reply":"2023-11-16T08:17:16.155585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer = preprocess(eng, fr)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:17:16.430210Z","iopub.execute_input":"2023-11-16T08:17:16.430528Z","iopub.status.idle":"2023-11-16T08:17:29.795015Z","shell.execute_reply.started":"2023-11-16T08:17:16.430502Z","shell.execute_reply":"2023-11-16T08:17:29.794214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preproc_english_sentences.shape,preproc_french_sentences.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:17:29.796586Z","iopub.execute_input":"2023-11-16T08:17:29.796951Z","iopub.status.idle":"2023-11-16T08:17:29.803619Z","shell.execute_reply.started":"2023-11-16T08:17:29.796919Z","shell.execute_reply":"2023-11-16T08:17:29.802481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preproc_english_sentences[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:18:00.853497Z","iopub.execute_input":"2023-11-16T08:18:00.853852Z","iopub.status.idle":"2023-11-16T08:18:00.860207Z","shell.execute_reply.started":"2023-11-16T08:18:00.853824Z","shell.execute_reply":"2023-11-16T08:18:00.859357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_english_sequence_length = preproc_english_sentences.shape[1]\nmax_french_sequence_length = preproc_french_sentences.shape[1]\nenglish_vocab_size = len(english_tokenizer.word_index)\nfrench_vocab_size = len(french_tokenizer.word_index)\n\nprint(\"Max English sentence length:\", max_english_sequence_length)\nprint(\"Max French sentence length:\", max_french_sequence_length)\nprint(\"English vocabulary size:\", english_vocab_size)\nprint(\"French vocabulary size:\", french_vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:18:21.704478Z","iopub.execute_input":"2023-11-16T08:18:21.705162Z","iopub.status.idle":"2023-11-16T08:18:21.711105Z","shell.execute_reply.started":"2023-11-16T08:18:21.705127Z","shell.execute_reply":"2023-11-16T08:18:21.710065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class positional_encoding(tf.keras.layers.Layer):\n    def __init__(self,max_sentence_len,embedding_size,**kwargs):\n        super().__init__(**kwargs)\n        \n        self.pos=np.arange(max_sentence_len).reshape(1,-1).T\n        self.i=np.arange(embedding_size/2).reshape(1,-1)\n        self.pos_emb=np.empty((1,max_sentence_len,embedding_size))\n        self.pos_emb[:,:,0 : :2]=np.sin(self.pos / np.power(10000, (2 * self.i / embedding_size)))\n        self.pos_emb[:,:,1 : :2]=np.cos(self.pos / np.power(10000, (2 * self.i / embedding_size)))\n        self.positional_embedding = tf.cast(self.pos_emb,dtype=tf.float32)\n        \n    def call(self, inputs):\n        return inputs + self.positional_embedding","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:18:51.263097Z","iopub.execute_input":"2023-11-16T08:18:51.263474Z","iopub.status.idle":"2023-11-16T08:18:51.271485Z","shell.execute_reply.started":"2023-11-16T08:18:51.263443Z","shell.execute_reply":"2023-11-16T08:18:51.270390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class paddding_mask(tf.keras.layers.Layer):\n    def __init__(self,**kwargs):\n        super().__init__(**kwargs)\n    def call(self,inputs):\n        mask=1-tf.cast(tf.math.equal(inputs,0),tf.float32)\n        return mask[:, tf.newaxis, :] ","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:47:35.405611Z","iopub.execute_input":"2023-11-16T09:47:35.405979Z","iopub.status.idle":"2023-11-16T09:47:35.412089Z","shell.execute_reply.started":"2023-11-16T09:47:35.405948Z","shell.execute_reply":"2023-11-16T09:47:35.411030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test():\n    a = positional_encoding(5,10)\n    print(a.pos)\n    print(a.i)\n    print(a.pos_emb)\n    print(a(np.ones((1,5,10))))\n    b = paddding_mask()\n    print(b([[1,2,3,4,0,0,0,1]]))\ntest()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:47:09.640889Z","iopub.execute_input":"2023-11-16T09:47:09.641277Z","iopub.status.idle":"2023-11-16T09:47:09.656380Z","shell.execute_reply.started":"2023-11-16T09:47:09.641246Z","shell.execute_reply":"2023-11-16T09:47:09.655447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paddding_mask()([[1,2,3,0]])","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:19:06.012825Z","iopub.execute_input":"2023-11-16T08:19:06.013262Z","iopub.status.idle":"2023-11-16T08:19:10.716539Z","shell.execute_reply.started":"2023-11-16T08:19:06.013225Z","shell.execute_reply":"2023-11-16T08:19:10.715630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class create_look_ahead_mask(tf.keras.layers.Layer):\n    def __init__(self,**kwargs):\n        super().__init__(**kwargs)\n    def call(self,sequence_length):\n        mask = tf.linalg.band_part(tf.ones((1, sequence_length, sequence_length)), -1, 0)\n        return mask ","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:19:10.718124Z","iopub.execute_input":"2023-11-16T08:19:10.718419Z","iopub.status.idle":"2023-11-16T08:19:10.724214Z","shell.execute_reply.started":"2023-11-16T08:19:10.718394Z","shell.execute_reply":"2023-11-16T08:19:10.723026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_look_ahead_mask()(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:20:13.146321Z","iopub.execute_input":"2023-11-16T08:20:13.146711Z","iopub.status.idle":"2023-11-16T08:20:13.166816Z","shell.execute_reply.started":"2023-11-16T08:20:13.146680Z","shell.execute_reply":"2023-11-16T08:20:13.165704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class input_layer_encoder(tf.keras.layers.Layer):\n    def __init__(self,max_sentence_len,embedding_size,vocab_size,**kwargs):\n        super().__init__(**kwargs)\n        self.paddding_mask=paddding_mask()\n        \n        self.embedding=tf.keras.layers.Embedding(vocab_size,\n                                                 embedding_size,\n                                                 input_length=max_sentence_len,\n                                                 input_shape=(max_sentence_len,))\n        \n        self.positional_encoding=positional_encoding(max_sentence_len,embedding_size)\n    def call(self,inputs):\n        mask=self.paddding_mask(inputs)\n        \n        emb=self.embedding(inputs)\n        \n        emb=self.positional_encoding(emb)\n        return emb,mask","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:20:28.912601Z","iopub.execute_input":"2023-11-16T08:20:28.912995Z","iopub.status.idle":"2023-11-16T08:20:28.920009Z","shell.execute_reply.started":"2023-11-16T08:20:28.912963Z","shell.execute_reply":"2023-11-16T08:20:28.918973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_e():\n    a = input_layer_encoder(5,10,10)\n    print(a(np.array([[6,7,8,1,4]])))\n    print(a.positional_encoding.positional_embedding)\ntest_e()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:27:20.396561Z","iopub.execute_input":"2023-11-16T09:27:20.396931Z","iopub.status.idle":"2023-11-16T09:27:20.415909Z","shell.execute_reply.started":"2023-11-16T09:27:20.396901Z","shell.execute_reply":"2023-11-16T09:27:20.414864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class input_layer_decoder(tf.keras.layers.Layer):\n    def __init__(self,max_sentence_len,embedding_size,vocab_size,**kwargs):\n        super().__init__(**kwargs)\n        self.paddding_mask=paddding_mask()\n        \n        self.embedding=tf.keras.layers.Embedding(vocab_size,\n                                                 embedding_size,\n                                                 input_length=max_sentence_len,\n                                                 input_shape=(max_sentence_len,))\n        \n        self.positional_encoding=positional_encoding(max_sentence_len,embedding_size)\n        \n        self.look_ahead_mask=create_look_ahead_mask()\n        self.max_sentence_len=max_sentence_len\n    def call(self,inputs):\n        mask=self.paddding_mask(inputs)\n        \n        emb=self.embedding(inputs)\n        \n        emb=self.positional_encoding(emb)\n        \n        look_head_mak=self.look_ahead_mask(self.max_sentence_len)\n        look_head_mak=tf.bitwise.bitwise_and(tf.cast(look_head_mak,dtype=np.int8),tf.cast(mask,dtype=np.int8))\n        return emb,look_head_mak","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:20:34.380495Z","iopub.execute_input":"2023-11-16T08:20:34.381329Z","iopub.status.idle":"2023-11-16T08:20:34.389321Z","shell.execute_reply.started":"2023-11-16T08:20:34.381294Z","shell.execute_reply":"2023-11-16T08:20:34.388134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_d():\n    a = input_layer_decoder(5,10,10)\n    print(a(np.ones((1,5))))\ntest_d()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:47:43.611164Z","iopub.execute_input":"2023-11-16T09:47:43.612090Z","iopub.status.idle":"2023-11-16T09:47:43.634291Z","shell.execute_reply.started":"2023-11-16T09:47:43.612052Z","shell.execute_reply":"2023-11-16T09:47:43.633248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder_layer(tf.keras.layers.Layer):\n    def __init__(self,\n                 embedding_size,\n                 heads_num,\n                 dense_num,\n                 dropout_rate=0.0,\n                 **kwargs):\n        \n        super().__init__(**kwargs)\n        \n        \n        self.multi_attention=tf.keras.layers.MultiHeadAttention(\n                num_heads=heads_num,\n                key_dim=embedding_size,\n                dropout=dropout_rate,\n            )\n        \n        self.Dropout=tf.keras.layers.Dropout(dropout_rate)\n        \n        self.ff=tf.keras.Sequential([\n            tf.keras.layers.Dense(dense_num,activation=\"relu\"),\n            tf.keras.layers.Dense(dense_num,activation=\"relu\"),\n            tf.keras.layers.Dense(dense_num,activation=\"relu\"),\n            tf.keras.layers.Dense(embedding_size,activation=\"relu\"),\n            tf.keras.layers.Dropout(dropout_rate)\n        ])\n        \n        self.add=tf.keras.layers.Add()\n        \n        self.norm1=tf.keras.layers.LayerNormalization()\n        self.norm2=tf.keras.layers.LayerNormalization()\n    def call(self,inputs,mask,training):\n        \n        mha=self.multi_attention(inputs,inputs,inputs,mask)\n        \n        norm=self.norm1(self.add([inputs,mha]))\n        \n        fc=self.ff(norm)\n        \n        A=self.Dropout(fc,training=training)\n        \n        output=self.norm2(self.add([A,norm]))\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:21:22.596214Z","iopub.execute_input":"2023-11-16T08:21:22.596888Z","iopub.status.idle":"2023-11-16T08:21:22.606811Z","shell.execute_reply.started":"2023-11-16T08:21:22.596855Z","shell.execute_reply":"2023-11-16T08:21:22.605826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(tf.keras.layers.Layer):\n    def __init__(self,\n                 max_sentence_len,\n                 embedding_size,\n                 vocab_size,\n                 heads_num,\n                 dense_num,\n                 num_of_encoders,\n                 **kwargs):\n        super().__init__(**kwargs)\n        self.add=tf.keras.layers.Add()\n        self.input_layer=input_layer_encoder(max_sentence_len,embedding_size,vocab_size)\n        self.encoder_layer=[Encoder_layer(embedding_size,heads_num, dense_num) for i in range (num_of_encoders)]\n        self.num_layers=num_of_encoders\n    def call(self,inputs,training):\n        emb,mask=self.input_layer(inputs)\n        skip=emb\n        for layer in self.encoder_layer:\n            emb = layer(emb, mask,training)\n            emb = self.add([skip,emb])\n            skip = emb\n        return emb,mask","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:21:22.899584Z","iopub.execute_input":"2023-11-16T08:21:22.900163Z","iopub.status.idle":"2023-11-16T08:21:22.907668Z","shell.execute_reply.started":"2023-11-16T08:21:22.900131Z","shell.execute_reply":"2023-11-16T08:21:22.906698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class decoder_layer(tf.keras.layers.Layer):\n    def __init__(self,\n                 embedding_size,\n                 heads_num,\n                 dense_num,\n                 dropout_rate=0.0,\n                 **kwargs):\n        \n        super().__init__(**kwargs)\n            \n        self.masked_mha=tf.keras.layers.MultiHeadAttention(\n                num_heads=heads_num,\n                key_dim=embedding_size,\n                dropout=dropout_rate,\n            )\n        \n        \n        self.multi_attention=tf.keras.layers.MultiHeadAttention(\n                num_heads=heads_num,\n                key_dim=embedding_size,\n                dropout=dropout_rate,\n            )\n        \n        self.ff=tf.keras.Sequential([\n            tf.keras.layers.Dense(dense_num,activation=\"relu\"),\n            tf.keras.layers.Dense(dense_num,activation=\"relu\"),\n            tf.keras.layers.Dense(dense_num,activation=\"relu\"),\n            tf.keras.layers.Dense(embedding_size,activation=\"relu\"),\n            tf.keras.layers.Dropout(dropout_rate)\n        ])\n        \n        self.Dropout=tf.keras.layers.Dropout(dropout_rate)\n        self.add=tf.keras.layers.Add()\n        \n        self.norm1=tf.keras.layers.LayerNormalization()\n        self.norm2=tf.keras.layers.LayerNormalization()\n        self.norm3=tf.keras.layers.LayerNormalization()\n        \n    def call(self,inputs,encoder_output,enc_mask,look_head_mask,training):\n        \n        mha_out,atten_score=self.masked_mha(inputs,inputs,inputs,look_head_mask,return_attention_scores=True)\n        \n        Q1=self.norm1(self.add([inputs,mha_out]))\n        \n        mha_out2,atten_score2=self.multi_attention(Q1,encoder_output,encoder_output,enc_mask,return_attention_scores=True)\n        \n        Z=self.norm2(self.add([Q1,mha_out2]))\n        \n        fc =  self.ff(Z)\n        \n        A=self.Dropout(fc,training=training)\n        \n        output=self.norm3(self.add([A,Z]))\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:21:23.274666Z","iopub.execute_input":"2023-11-16T08:21:23.275333Z","iopub.status.idle":"2023-11-16T08:21:23.286459Z","shell.execute_reply.started":"2023-11-16T08:21:23.275300Z","shell.execute_reply":"2023-11-16T08:21:23.285567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decoder(tf.keras.layers.Layer):\n    def __init__(self,\n                 max_sentence_len,\n                 embedding_size,\n                 vocab_size,\n                 heads_num,\n                 dense_num,\n                 num_of_decoders,\n                 **kwargs):\n        super().__init__(**kwargs)\n        self.add=tf.keras.layers.Add()\n        self.input_layer=input_layer_decoder(max_sentence_len,embedding_size,vocab_size)\n        self.decoder_layer=[decoder_layer(embedding_size,heads_num, dense_num) for i in range (num_of_decoders)]\n        self.num_layers=num_of_decoders\n    def call(self,inputs,encoder_output,enc_mask,training):\n        emb,look_head_mask=self.input_layer(inputs)\n        skip=emb\n        for layer in self.decoder_layer:\n            emb = layer(emb,encoder_output,enc_mask,look_head_mask,training)\n            emb = self.add([skip,emb])\n            skip = emb\n        return emb","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:21:23.658964Z","iopub.execute_input":"2023-11-16T08:21:23.659780Z","iopub.status.idle":"2023-11-16T08:21:23.667514Z","shell.execute_reply.started":"2023-11-16T08:21:23.659745Z","shell.execute_reply":"2023-11-16T08:21:23.666434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class transformer(tf.keras.Model):\n    def __init__(self,\n                 max_sentence_len_1=None,max_sentence_len_2=None,embedding_size=None,vocab_size1=None,vocab_size2=None,\n                         heads_num=None,dense_num=None,num_of_encoders_decoders=None):\n\n        super(transformer,self).__init__()\n\n        self.Encoder=Encoder(max_sentence_len_1,embedding_size,vocab_size1,heads_num,dense_num,num_of_encoders_decoders)\n        self.Decoder=Decoder(max_sentence_len_2,embedding_size,vocab_size2,heads_num,dense_num,num_of_encoders_decoders)\n        self.Final_layer=tf.keras.layers.Dense(vocab_size2, activation='relu')\n        self.softmax=tf.keras.layers.Softmax(axis=-1)\n    def call(self, inputs):\n        input_sentence,output_sentence=inputs\n        enc_output,enc_mask=self.Encoder(input_sentence)\n\n        dec_output=self.Decoder(output_sentence,enc_output,enc_mask)\n\n        final_out=self.Final_layer(dec_output)\n\n        softmax_out=self.softmax(final_out)\n        return softmax_out","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:23:46.289098Z","iopub.execute_input":"2023-11-16T08:23:46.289457Z","iopub.status.idle":"2023-11-16T08:23:46.298254Z","shell.execute_reply.started":"2023-11-16T08:23:46.289427Z","shell.execute_reply":"2023-11-16T08:23:46.297051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tran=transformer(max_sentence_len_1=14,\n                     max_sentence_len_2=13,\n                     embedding_size=300,\n                     vocab_size1=french_vocab_size+1,\n                     vocab_size2=english_vocab_size+1,\n                     heads_num=5,\n                     dense_num=512,\n                     num_of_encoders_decoders=2)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:23:46.527651Z","iopub.execute_input":"2023-11-16T08:23:46.527964Z","iopub.status.idle":"2023-11-16T08:23:46.599465Z","shell.execute_reply.started":"2023-11-16T08:23:46.527937Z","shell.execute_reply":"2023-11-16T08:23:46.598744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tran((preproc_french_sentences[:1],preproc_english_sentences[:1,:-1]))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:23:46.755698Z","iopub.execute_input":"2023-11-16T08:23:46.756303Z","iopub.status.idle":"2023-11-16T08:23:47.145842Z","shell.execute_reply.started":"2023-11-16T08:23:46.756274Z","shell.execute_reply":"2023-11-16T08:23:47.144848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tran.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n             optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n             metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:23:47.147693Z","iopub.execute_input":"2023-11-16T08:23:47.148452Z","iopub.status.idle":"2023-11-16T08:23:47.161500Z","shell.execute_reply.started":"2023-11-16T08:23:47.148413Z","shell.execute_reply":"2023-11-16T08:23:47.160605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tran.fit((preproc_french_sentences,preproc_english_sentences[:,:-1]),\n         preproc_english_sentences[:,1:,tf.newaxis],\n         epochs=10, verbose = True,\n         batch_size=1024)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:31:46.463477Z","iopub.execute_input":"2023-11-16T08:31:46.463829Z","iopub.status.idle":"2023-11-16T08:55:40.122116Z","shell.execute_reply.started":"2023-11-16T08:31:46.463804Z","shell.execute_reply":"2023-11-16T08:55:40.121162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preproc_french_sentences[0][np.newaxis,...].shape","metadata":{"execution":{"iopub.status.busy":"2023-11-08T18:23:18.790018Z","iopub.execute_input":"2023-11-08T18:23:18.790386Z","iopub.status.idle":"2023-11-08T18:23:18.796488Z","shell.execute_reply.started":"2023-11-08T18:23:18.790360Z","shell.execute_reply":"2023-11-08T18:23:18.795613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fr_tk","metadata":{"execution":{"iopub.status.busy":"2023-11-08T18:26:50.661107Z","iopub.execute_input":"2023-11-08T18:26:50.661691Z","iopub.status.idle":"2023-11-08T18:26:50.694987Z","shell.execute_reply.started":"2023-11-08T18:26:50.661660Z","shell.execute_reply":"2023-11-08T18:26:50.693707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tran.predict((preproc_english_sentences[0][np.newaxis,...],french_tokenizer.texts_to_sequences('<SOS>')))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = Encoder_layer(10,3,10)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T18:18:51.714414Z","iopub.execute_input":"2023-11-08T18:18:51.714796Z","iopub.status.idle":"2023-11-08T18:18:51.734133Z","shell.execute_reply.started":"2023-11-08T18:18:51.714767Z","shell.execute_reply":"2023-11-08T18:18:51.733141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.models.save_model(tran,'/kaggle/working/Transformer_en_fr.h5',save_format=\"tf\")","metadata":{"execution":{"iopub.status.busy":"2023-11-08T18:14:27.793735Z","iopub.execute_input":"2023-11-08T18:14:27.794396Z","iopub.status.idle":"2023-11-08T18:14:27.855038Z","shell.execute_reply.started":"2023-11-08T18:14:27.794362Z","shell.execute_reply":"2023-11-08T18:14:27.853656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_pred(sent):\n    output=english_tokenizer.texts_to_sequences(sent)\n    output=pad(output,13)\n    return output","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:55:49.547856Z","iopub.execute_input":"2023-11-16T08:55:49.548536Z","iopub.status.idle":"2023-11-16T08:55:49.553590Z","shell.execute_reply.started":"2023-11-16T08:55:49.548498Z","shell.execute_reply":"2023-11-16T08:55:49.552564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred(i):\n    sent=[\"<SOS>\"]\n    french_token=prepare_pred(sent)\n    word=np.argmax(tran.predict((preproc_french_sentences[[i]],french_token),verbose=0),-1)[0,0]\n    sent[0]=sent[0]+ \" \"+english_tokenizer.sequences_to_texts(np.array([[word]]))[0]\n    for j in range(1,12):\n        french_token=prepare_pred(sent)\n        word=np.argmax(tran.predict((preproc_french_sentences[[i]],french_token),verbose=0),-1)[0,j]\n        sent[0]=sent[0]+ \" \"+english_tokenizer.sequences_to_texts(np.array([[word]]))[0]\n        if english_tokenizer.sequences_to_texts(np.array([[word]]))[0]==\"eos\":\n            break\n    return sent","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:55:49.784035Z","iopub.execute_input":"2023-11-16T08:55:49.784876Z","iopub.status.idle":"2023-11-16T08:55:49.791898Z","shell.execute_reply.started":"2023-11-16T08:55:49.784840Z","shell.execute_reply":"2023-11-16T08:55:49.791122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"french_tokenizer.texts_to_sequences([\"comment allez-vous\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:54:05.923937Z","iopub.execute_input":"2023-11-16T09:54:05.924353Z","iopub.status.idle":"2023-11-16T09:54:05.931631Z","shell.execute_reply.started":"2023-11-16T09:54:05.924319Z","shell.execute_reply":"2023-11-16T09:54:05.930480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sent=[\"hello\"]\nfrench_token=prepare_pred(sent)\nword=np.argmax(tran.predict((pad(french_tokenizer.texts_to_sequences([\"je ne peux pas garder ceci\"])),french_token),verbose=0),-1)[0,0]\nsent[0]=sent[0]+ \" \"+english_tokenizer.sequences_to_texts(np.array([[word]]))[0]\nfor j in range(1,12):\n    french_token=prepare_pred(sent)\n    word=np.argmax(tran.predict((preproc_french_sentences[[i]],french_token),verbose=0),-1)[0,j]\n    sent[0]=sent[0]+ \" \"+english_tokenizer.sequences_to_texts(np.array([[word]]))[0]\n    if english_tokenizer.sequences_to_texts(np.array([[word]]))[0]==\"eos\":\n        break","metadata":{"execution":{"iopub.status.busy":"2023-11-16T10:09:00.220729Z","iopub.execute_input":"2023-11-16T10:09:00.221090Z","iopub.status.idle":"2023-11-16T10:09:00.824606Z","shell.execute_reply.started":"2023-11-16T10:09:00.221056Z","shell.execute_reply":"2023-11-16T10:09:00.823528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"french_tokenizer.sequences_to_texts([preproc_french_sentences[100]])","metadata":{"execution":{"iopub.status.busy":"2023-11-16T10:09:00.826397Z","iopub.execute_input":"2023-11-16T10:09:00.826705Z","iopub.status.idle":"2023-11-16T10:09:00.833359Z","shell.execute_reply.started":"2023-11-16T10:09:00.826680Z","shell.execute_reply":"2023-11-16T10:09:00.832381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"english_tokenizer.sequences_to_texts([preproc_english_sentences[100]])","metadata":{"execution":{"iopub.status.busy":"2023-11-16T10:09:00.834554Z","iopub.execute_input":"2023-11-16T10:09:00.834878Z","iopub.status.idle":"2023-11-16T10:09:00.848055Z","shell.execute_reply.started":"2023-11-16T10:09:00.834844Z","shell.execute_reply":"2023-11-16T10:09:00.847297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sent","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:55:50.032046Z","iopub.execute_input":"2023-11-16T08:55:50.032809Z","iopub.status.idle":"2023-11-16T08:55:50.036490Z","shell.execute_reply.started":"2023-11-16T08:55:50.032778Z","shell.execute_reply":"2023-11-16T08:55:50.035612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show():\n    i=random.randint(0,170111)\n    print(\"french sent : \",french_tokenizer.sequences_to_texts(preproc_french_sentences[[i]]))\n    print(\"predict sent : \",pred(i))\n    print(\"true sent : \",english_tokenizer.sequences_to_texts(preproc_english_sentences[[i]]))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T08:55:50.284395Z","iopub.execute_input":"2023-11-16T08:55:50.284670Z","iopub.status.idle":"2023-11-16T08:55:50.289612Z","shell.execute_reply.started":"2023-11-16T08:55:50.284646Z","shell.execute_reply":"2023-11-16T08:55:50.288808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    show()\n    print(\"----------------\")","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:50:10.427006Z","iopub.execute_input":"2023-11-16T09:50:10.428014Z","iopub.status.idle":"2023-11-16T09:50:16.165140Z","shell.execute_reply.started":"2023-11-16T09:50:10.427969Z","shell.execute_reply":"2023-11-16T09:50:16.164218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-10-29T12:43:25.948172Z","iopub.status.idle":"2023-10-29T12:43:25.948523Z","shell.execute_reply.started":"2023-10-29T12:43:25.948363Z","shell.execute_reply":"2023-10-29T12:43:25.948379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# With Hugging Face Transformers","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:28.978901Z","iopub.execute_input":"2023-12-05T15:47:28.979742Z","iopub.status.idle":"2023-12-05T15:47:28.983730Z","shell.execute_reply.started":"2023-12-05T15:47:28.979706Z","shell.execute_reply":"2023-12-05T15:47:28.982833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/language-translation-englishfrench/eng_-french.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:29.180761Z","iopub.execute_input":"2023-12-05T15:47:29.181448Z","iopub.status.idle":"2023-12-05T15:47:29.492070Z","shell.execute_reply.started":"2023-12-05T15:47:29.181417Z","shell.execute_reply":"2023-12-05T15:47:29.491067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:29.493715Z","iopub.execute_input":"2023-12-05T15:47:29.494117Z","iopub.status.idle":"2023-12-05T15:47:29.503694Z","shell.execute_reply.started":"2023-12-05T15:47:29.494081Z","shell.execute_reply":"2023-12-05T15:47:29.502769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.sample(frac=1).reset_index(drop=True)\ndata.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:29.571667Z","iopub.execute_input":"2023-12-05T15:47:29.571963Z","iopub.status.idle":"2023-12-05T15:47:29.611618Z","shell.execute_reply.started":"2023-12-05T15:47:29.571938Z","shell.execute_reply":"2023-12-05T15:47:29.610625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_texts = data['English words/sentences'][:1000]\ntarget_texts = data['French words/sentences'][:1000]","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:29.760607Z","iopub.execute_input":"2023-12-05T15:47:29.760912Z","iopub.status.idle":"2023-12-05T15:47:29.765856Z","shell.execute_reply.started":"2023-12-05T15:47:29.760885Z","shell.execute_reply":"2023-12-05T15:47:29.764915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:29.953895Z","iopub.execute_input":"2023-12-05T15:47:29.954229Z","iopub.status.idle":"2023-12-05T15:47:29.958879Z","shell.execute_reply.started":"2023-12-05T15:47:29.954198Z","shell.execute_reply":"2023-12-05T15:47:29.957775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\nmodel = TFAutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:30.126147Z","iopub.execute_input":"2023-12-05T15:47:30.126481Z","iopub.status.idle":"2023-12-05T15:47:31.516091Z","shell.execute_reply.started":"2023-12-05T15:47:30.126452Z","shell.execute_reply":"2023-12-05T15:47:31.515167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_encodings = tokenizer(list(input_texts), return_tensors=\"tf\", padding=True, truncation=True)\ntarget_encodings = tokenizer(list(target_texts), return_tensors=\"tf\", padding=True, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:31.517774Z","iopub.execute_input":"2023-12-05T15:47:31.518082Z","iopub.status.idle":"2023-12-05T15:47:31.593972Z","shell.execute_reply.started":"2023-12-05T15:47:31.518052Z","shell.execute_reply":"2023-12-05T15:47:31.593273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_encodings","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:31.594946Z","iopub.execute_input":"2023-12-05T15:47:31.595226Z","iopub.status.idle":"2023-12-05T15:47:31.603919Z","shell.execute_reply.started":"2023-12-05T15:47:31.595195Z","shell.execute_reply":"2023-12-05T15:47:31.602998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_encodings","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:31.606408Z","iopub.execute_input":"2023-12-05T15:47:31.607089Z","iopub.status.idle":"2023-12-05T15:47:31.616369Z","shell.execute_reply.started":"2023-12-05T15:47:31.607052Z","shell.execute_reply":"2023-12-05T15:47:31.615409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder_input_ids = target_encodings[\"input_ids\"]","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:31.617679Z","iopub.execute_input":"2023-12-05T15:47:31.618106Z","iopub.status.idle":"2023-12-05T15:47:31.625642Z","shell.execute_reply.started":"2023-12-05T15:47:31.618064Z","shell.execute_reply":"2023-12-05T15:47:31.624857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder_input_ids","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:31.626703Z","iopub.execute_input":"2023-12-05T15:47:31.627006Z","iopub.status.idle":"2023-12-05T15:47:31.640566Z","shell.execute_reply.started":"2023-12-05T15:47:31.626969Z","shell.execute_reply":"2023-12-05T15:47:31.639493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices(\n    (dict(input_encodings), decoder_input_ids)\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:31.643521Z","iopub.execute_input":"2023-12-05T15:47:31.643819Z","iopub.status.idle":"2023-12-05T15:47:31.652826Z","shell.execute_reply.started":"2023-12-05T15:47:31.643783Z","shell.execute_reply":"2023-12-05T15:47:31.651954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:33.150881Z","iopub.execute_input":"2023-12-05T15:47:33.151828Z","iopub.status.idle":"2023-12-05T15:47:33.158086Z","shell.execute_reply.started":"2023-12-05T15:47:33.151789Z","shell.execute_reply":"2023-12-05T15:47:33.156979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\ntrain_dataset = train_dataset.batch(batch_size)\n\n# Training settings\nnum_epochs = 3\nlearning_rate = 1e-4\n\n# Optimizer and loss function\noptimizer = tf.keras.optimizers.Adam(learning_rate)\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\n# Training loop\nfor epoch in range(num_epochs):\n    total_loss = 0.0\n    for batch in train_dataset:\n        inputs = batch[0]\n        decoder_input_ids = batch[1]\n\n        with tf.GradientTape() as tape:\n            outputs = model(inputs, decoder_input_ids=decoder_input_ids)\n            logits = outputs.logits\n\n            # Calculate loss\n            loss = loss_fn(decoder_input_ids, logits)\n            total_loss += loss.numpy()\n\n        # Update model weights\n        gradients = tape.gradient(loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    average_loss = total_loss / len(train_dataset)\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}\")\n\n# Save the trained model and tokenizer\nmodel.save_pretrained(\"translation_model_tf\")\ntokenizer.save_pretrained(\"translation_model_tf\")","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:47:34.178609Z","iopub.execute_input":"2023-12-05T15:47:34.178972Z","iopub.status.idle":"2023-12-05T15:48:51.562998Z","shell.execute_reply.started":"2023-12-05T15:47:34.178943Z","shell.execute_reply":"2023-12-05T15:48:51.561910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_text = \" want you to wear this one.\"\n\n# Tokenize the input text\ninput_encoding = tokenizer(input_text, return_tensors=\"tf\", padding=True, truncation=True)\n\n# Make predictions\nwith tf.device('/CPU:0'):  # Adjust device as needed\n    output_ids = model.generate(input_encoding[\"input_ids\"])\n\n# Decode the generated output\noutput_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n\nprint(\"Input Text:\", input_text)\nprint(\"Generated Translation:\", output_text)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:49:57.027888Z","iopub.execute_input":"2023-12-05T15:49:57.029140Z","iopub.status.idle":"2023-12-05T15:50:01.357594Z","shell.execute_reply.started":"2023-12-05T15:49:57.029090Z","shell.execute_reply":"2023-12-05T15:50:01.356473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_texts","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:49:50.018645Z","iopub.execute_input":"2023-12-05T15:49:50.019040Z","iopub.status.idle":"2023-12-05T15:49:50.027553Z","shell.execute_reply.started":"2023-12-05T15:49:50.018995Z","shell.execute_reply":"2023-12-05T15:49:50.026543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}