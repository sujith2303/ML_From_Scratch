{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:02:40.882594Z","iopub.execute_input":"2024-12-01T10:02:40.883061Z","iopub.status.idle":"2024-12-01T10:02:45.671782Z","shell.execute_reply.started":"2024-12-01T10:02:40.883022Z","shell.execute_reply":"2024-12-01T10:02:45.670475Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"![image.png](attachment:d96c8750-85dd-4b03-9398-4fef19249ebb.png)![image.png](attachment:99008ed9-d692-4fff-b049-5f824993eacf.png)","metadata":{},"attachments":{"d96c8750-85dd-4b03-9398-4fef19249ebb.png":{"image/png":"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"},"99008ed9-d692-4fff-b049-5f824993eacf.png":{"image/png":"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"}}},{"cell_type":"code","source":"# class PositionalEmbeddings(nn.Module):\n#     def __init__(self, max_seq_length, embedding_dimension, device='cpu'):\n#         super().__init__()\n#         self.device = device\n#         self.max_seq_length = max_seq_length\n#         self.d = embedding_dimension\n#         self.pos = torch.arange(0, self.max_seq_length, device=device).unsqueeze(0).unsqueeze(-1)\n#         self.i = torch.arange(0, self.d // 2, device=device).unsqueeze(0).unsqueeze(0)\n#         self.pos_embedding = torch.empty(1, self.max_seq_length, self.d, device=device)\n#         self.pos_embedding[:, :, 0::2] = torch.sin(self.pos / torch.pow(10000, (2 * self.i / self.d)))\n#         self.pos_embedding[:, :, 1::2] = torch.cos(self.pos / torch.pow(10000, (2 * self.i / self.d)))\n\n#     def forward(self, x):\n#         return x + self.pos_embedding[:, :x.size(1), :].to(self.device)\n","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-01T10:02:45.674398Z","iopub.execute_input":"2024-12-01T10:02:45.675246Z","iopub.status.idle":"2024-12-01T10:02:45.681487Z","shell.execute_reply.started":"2024-12-01T10:02:45.675189Z","shell.execute_reply":"2024-12-01T10:02:45.680253Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class PaddingMask(nn.Module):\n    def __init__(self,pad_token_id = 0,device='cpu'):\n        super().__init__()\n        self.device = device\n        self.pad_token_id = pad_token_id\n\n    def forward(self, x):\n        return (x == self.pad_token_id).to(self.device)\n\nclass LookaheadMask(nn.Module):\n    # True to ignore\n    def __init__(self, pad_token_id = 0,device='cpu'):\n        super().__init__()\n        self.device = device\n        self.pad_token_id = pad_token_id\n    def forward(self,tgt,tgt_pad_mask =None):\n        tgt_seq_length = tgt.size(1)\n        if not tgt_pad_mask:\n            tgt_pad_mask = PaddingMask(pad_token_id = self.pad_token_id,device = self.device)(tgt).unsqueeze(1)\n        \n        tgt_causal_mask = torch.tril(torch.ones(\n            tgt_seq_length, tgt_seq_length, device=tgt.device\n        )).bool()\n        tgt_mask = ~tgt_pad_mask & tgt_causal_mask\n        return ~tgt_mask.to(self.device)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:02:45.682802Z","iopub.execute_input":"2024-12-01T10:02:45.683271Z","iopub.status.idle":"2024-12-01T10:02:45.712030Z","shell.execute_reply.started":"2024-12-01T10:02:45.683223Z","shell.execute_reply":"2024-12-01T10:02:45.710507Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"LookaheadMask()(batch['input_ids']).shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:02:45.714856Z","iopub.execute_input":"2024-12-01T10:02:45.715482Z","iopub.status.idle":"2024-12-01T10:02:46.022392Z","shell.execute_reply.started":"2024-12-01T10:02:45.715401Z","shell.execute_reply":"2024-12-01T10:02:46.020481Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m LookaheadMask()(\u001b[43mbatch\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mshape\n","\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"],"ename":"NameError","evalue":"name 'batch' is not defined","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"class PositionalEmbeddings(nn.Module):\n    def __init__(self,device = 'cpu'):\n        super().__init__()\n        self.device = device\n    \n    def forward(self,x):\n        shape = x.shape\n        if len(shape)==3:\n            batch_size,max_seq_len,d_model = shape\n        else:\n            max_seq_len,d_model = shape\n        pos = torch.arange(0,max_seq_len,device = self.device).unsqueeze(1)\n        i = torch.arange(0,d_model//2,device = self.device)\n        pe =  torch.zeros(max_seq_len,d_model,device = self.device)\n        pe[:,0::2] = torch.sin(pos/(10000**(2*i/d_model)))\n        pe[:,1::2] = torch.cos(pos/(10000**(2*i/d_model)))\n        if len(x.shape)==3:\n            return pe.unsqueeze(0)+x\n        return pe+x\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:02:52.493450Z","iopub.execute_input":"2024-12-01T10:02:52.494744Z","iopub.status.idle":"2024-12-01T10:02:52.506867Z","shell.execute_reply.started":"2024-12-01T10:02:52.494678Z","shell.execute_reply":"2024-12-01T10:02:52.504781Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"class RotaryPositionalEmbeddings(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.positional_embeddings = PositionalEmbeddings()\n        \n    def forward(self,x):\n        pe =  self.positional_embeddings(x)\n        x1,x2 = pe.chunk(2,-1)\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:57:08.420221Z","iopub.execute_input":"2024-12-01T09:57:08.420626Z","iopub.status.idle":"2024-12-01T09:57:08.426808Z","shell.execute_reply.started":"2024-12-01T09:57:08.420592Z","shell.execute_reply":"2024-12-01T09:57:08.425571Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class MultiQueryAttention(nn.Module):\n    def __init__(self,embed_dim,num_query_heads,device = 'cpu'):\n        super().__init__()\n        assert embed_dim%num_query_heads==0 , \"Embedding Dimension must be divisible by Num Heads\"\n        self.head_dim = embed_dim//num_query_heads\n        self.num_query_heads = num_query_heads\n        self.q_proj = nn.Linear(embed_dim,embed_dim)\n        self.k_proj = nn.Linear(self.head_dim,embed_dim)\n        self.v_proj = nn.Linear(self.head_dim,embed_dim)\n        self.out_proj = nn.Linear(embed_dim,embed_dim)\n        # n,head_dim,d_model\n        # q = n,head_d,d_model\n        # k = head_d,d_model\n        # v = head_d,d_model\n        # q.kT --> n,head_d,head_d\n        # q.KT.v --> n,head_d,d_model\n        \n\n    def forward(self,x,attn_mask = None):\n        batch_size,seq_length,embedding_dimension = x.shape\n        q = self.q_proj(x).view(batch_size,self.num_query_heads,seq_length,self.head_dim)\n        k = self.v_proj(x).view(batch_size,seq_length,self.head_dim)\n        v = self.v_proj(x).view(batch_size,seq_length,self.head_dim)\n\n        attn_scores = torch.matmul(q,k.transpose(-2,-1))/(self.head_dim**0.5)  # batch_size,num_heads,seq,seq\n        if attn_mask is not None:\n            attn_scores = attn_scores.masked_fill(mask==True,float(\"-inf\"))\n        attn_probs = nn.functional.softmax(attn_scores,dim=-1)\n        attn_outs = torch.matmul(attn_probs,v).contiguous().view(batch_size,seq_length,embedding_dimension)      # batch_size,num_heads,seq,head_dim\n        output = self.out_proj(attn_outs)\n        return output,attn_probs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GroupedQueryAttention(nn.Module):\n    def __init__(self,embed_dim,num_heads,device = 'cpu'):\n        super().__init__()\n\n    def forward(self):\n        pass","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self,embed_dim,num_heads,device = 'cpu'):\n        super().__init__()\n        self.num_heads = num_heads\n        assert embed_dim%num_heads ==0 , \"Embedding Dimension must be divisible by Num Heads\"\n        self.head_dim = embed_dim//num_heads\n        self.q_proj = nn.Linear(embed_dim,embed_dim,device = device)\n        self.k_proj = nn.Linear(embed_dim,embed_dim,device = device)\n        self.v_proj = nn.Linear(embed_dim,embed_dim,device = device)\n        self.out_proj = nn.Linear(embed_dim,embed_dim,device = device)\n\n    def forward(self,x,y,z ,attn_mask=None):\n        batch_size,seq_len,embed_dim = x.shape\n        q = self.q_proj(x).view(batch_size,self.num_heads,seq_len,self.head_dim)\n        k = self.k_proj(y).view(batch_size,self.num_heads,seq_len,self.head_dim)\n        v = self.v_proj(z).view(batch_size,self.num_heads,seq_len,self.head_dim)\n\n        attn_scores = torch.matmul(q,k.transpose(-2,-1))/(self.head_dim ** 0.5)\n        if attn_mask is not None:\n            attn_scores = attn_scores.masked_fill(attn_mask==True,float('-inf'))\n        attn_probs = nn.functional.softmax(attn_scores,dim=-1)\n\n        attn_outs = torch.matmul(v.transpose(-2,-1),attn_probs).contiguous().view(batch_size,seq_len,embed_dim)\n        output = self.out_proj(attn_outs)\n        return output,attn_probs\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:02:57.166828Z","iopub.execute_input":"2024-12-01T10:02:57.167432Z","iopub.status.idle":"2024-12-01T10:02:57.184918Z","shell.execute_reply.started":"2024-12-01T10:02:57.167354Z","shell.execute_reply":"2024-12-01T10:02:57.183492Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Decoder_block(nn.Module):\n  def __init__(self,\n               d_model=512,\n               num_heads=8,\n               num_dense_units = 2048,\n               vocab_size = 50257,\n               dropout_ratio = 0.1,\n               device = 'cpu'):\n    super().__init__()\n    self.device = device\n    self.num_heads = num_heads\n    self.mha = MultiHeadAttention(embed_dim = d_model,\n                                     num_heads = num_heads,\n                                     device = device)\n    self.linear = nn.Sequential(\n        nn.Linear(d_model,num_dense_units,bias = True),\n        nn.Dropout(dropout_ratio,inplace = False),\n        nn.Linear(num_dense_units,d_model,bias=True)\n    ).to(device)\n    self.norm1 = nn.LayerNorm(d_model,device=  device)\n    self.norm2 = nn.LayerNorm(d_model,device = device)\n\n  def forward(self,x,mask):\n    mask = mask.repeat(self.num_heads,1,1,1).transpose(0,1).to(self.device)\n    res = x\n    x = self.mha(x,x,x,attn_mask = mask)[0]\n    x = x+res\n    x = self.norm1(x)\n\n    res = x\n    x = self.linear(x)\n    x = x+res\n    x = self.norm2(x)\n\n    return x\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:02:57.464297Z","iopub.execute_input":"2024-12-01T10:02:57.465547Z","iopub.status.idle":"2024-12-01T10:02:57.475794Z","shell.execute_reply.started":"2024-12-01T10:02:57.465499Z","shell.execute_reply":"2024-12-01T10:02:57.474276Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"(torch.zeros(64, 512, 512).repeat(8,1,1,1)).shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:02:57.995270Z","iopub.execute_input":"2024-12-01T10:02:57.995924Z","iopub.status.idle":"2024-12-01T10:02:58.562184Z","shell.execute_reply.started":"2024-12-01T10:02:57.995865Z","shell.execute_reply":"2024-12-01T10:02:58.560538Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"torch.Size([8, 64, 512, 512])"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"class GPT2(nn.Module):\n  def __init__(self,\n               d_model=512,\n               max_seq_len = 512,\n               num_heads=8,\n               num_decoder_layer = 6,\n               num_dense_units = 2048,\n               vocab_size = 32100,\n               dropout_ratio = 0.1,\n               padding_token = 0,\n               device = 'cpu'):\n    super().__init__()\n    self.device = device\n    self.num_decoder_layer  =num_decoder_layer\n    self.Embeddings = nn.Embedding(vocab_size,d_model,device = device)\n    self.positional_embeddings = PositionalEmbeddings(device= device)\n    self.mask = LookaheadMask(padding_token,device)\n    self.decoder_layers = nn.ModuleList([Decoder_block(d_model,num_heads,num_dense_units,vocab_size,dropout_ratio,device) for _ in range(num_decoder_layer)])\n    self.final_layer = nn.Linear(d_model,vocab_size,device =  device)\n\n\n  def forward(self,x,mask = None):\n    mask = self.mask(x)\n    x = self.Embeddings(x)\n    x = self.positional_embeddings(x)\n    for i in range(self.num_decoder_layer):\n        x = self.decoder_layers[i](x,mask)\n    x = self.final_layer(x)\n    return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:05:49.740169Z","iopub.execute_input":"2024-12-01T10:05:49.741374Z","iopub.status.idle":"2024-12-01T10:05:49.752931Z","shell.execute_reply.started":"2024-12-01T10:05:49.741329Z","shell.execute_reply":"2024-12-01T10:05:49.750206Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"# Loading Tokenizer & Data","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('HuggingFaceTB/SmolLM2-360M-Instruct')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:03:02.938627Z","iopub.execute_input":"2024-12-01T10:03:02.939062Z","iopub.status.idle":"2024-12-01T10:03:06.350835Z","shell.execute_reply.started":"2024-12-01T10:03:02.939027Z","shell.execute_reply":"2024-12-01T10:03:06.349377Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.76k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89e54db4f7c34747b12bac7c314001a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a66790d3e76c4251a4acbfb3ce79bd4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce0ac9e5ff1844e99d8b90f88860fec2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e61bb9b0dee24ff4a5e2f978c8ea60bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/655 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d67bf8ca141410b889747035e90d1de"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:03:06.353375Z","iopub.execute_input":"2024-12-01T10:03:06.354134Z","iopub.status.idle":"2024-12-01T10:03:07.594190Z","shell.execute_reply.started":"2024-12-01T10:03:06.354076Z","shell.execute_reply":"2024-12-01T10:03:07.592520Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"dataset = load_dataset('HuggingFaceTB/smoltalk','explore-instruct-rewriting')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:03:07.595649Z","iopub.execute_input":"2024-12-01T10:03:07.596244Z","iopub.status.idle":"2024-12-01T10:03:10.011924Z","shell.execute_reply.started":"2024-12-01T10:03:07.596206Z","shell.execute_reply":"2024-12-01T10:03:10.010274Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/9.25k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5895a50c1e894d82960a2be317e04405"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/5.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9c321a5f8ce44b7834070a269f40378"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/285k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4902e12449bd44a2aa3486473be75c9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/30400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c7142a3ac7842a784a8b7f76c4f2c94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"446a968fb7754066bf63e488cf68c2e8"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:03:10.015951Z","iopub.execute_input":"2024-12-01T10:03:10.016879Z","iopub.status.idle":"2024-12-01T10:03:10.026820Z","shell.execute_reply.started":"2024-12-01T10:03:10.016811Z","shell.execute_reply":"2024-12-01T10:03:10.025140Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['messages'],\n        num_rows: 30400\n    })\n    test: Dataset({\n        features: ['messages'],\n        num_rows: 1600\n    })\n})"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset['train'][0]['messages']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:03:10.028353Z","iopub.execute_input":"2024-12-01T10:03:10.028879Z","iopub.status.idle":"2024-12-01T10:03:10.052902Z","shell.execute_reply.started":"2024-12-01T10:03:10.028825Z","shell.execute_reply":"2024-12-01T10:03:10.051130Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[{'content': \"You are an AI rewriting assistant. You will be provided with a text and you need to rewrite it according to the user's instructions.\",\n  'role': 'system'},\n {'content': 'Create a table of contents for this long article to enhance its organization and navigation:\\nThis article explores the history and cultural significance of tattoos, including their origins in ancient civilizations, their use in religious ceremonies, and their evolution into mainstream fashion statements.',\n  'role': 'user'},\n {'content': 'Table of Contents\\nI. Introduction\\nII. Origins in Ancient Civilizations\\nIII. Use in Religious Ceremonies \\nIV. Evolution to Mainstream Fashion Statements\\nV. Conclusion',\n  'role': 'assistant'}]"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"d_model=768\nmax_seq_len = 512\nnum_heads=12\nnum_decoder_layer = 6\nnum_dense_units = 3072\nvocab_size = tokenizer.vocab_size\ndropout_rate = 0.1\npadding_token = tokenizer.pad_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:20:13.426627Z","iopub.execute_input":"2024-12-01T10:20:13.427216Z","iopub.status.idle":"2024-12-01T10:20:13.435106Z","shell.execute_reply.started":"2024-12-01T10:20:13.427175Z","shell.execute_reply":"2024-12-01T10:20:13.433544Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"def tokenize(example):\n    example['input_ids'] = tokenizer.apply_chat_template(dataset['train'][0]['messages'],\n                                                         padding = \"max_length\",\n                                                         max_length = max_seq_len,\n                                                         return_tensors='pt',\n                                                         truncation = True).squeeze(0)\n    return example","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:03:16.000746Z","iopub.execute_input":"2024-12-01T10:03:16.001160Z","iopub.status.idle":"2024-12-01T10:03:16.008160Z","shell.execute_reply.started":"2024-12-01T10:03:16.001125Z","shell.execute_reply":"2024-12-01T10:03:16.006896Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"tokenizer.apply_chat_template(dataset['train'][0]['messages'], padding = \"max_length\",max_length = 512,return_tensors='pt',truncation = True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:03:16.604428Z","iopub.execute_input":"2024-12-01T10:03:16.604886Z","iopub.status.idle":"2024-12-01T10:03:16.662048Z","shell.execute_reply.started":"2024-12-01T10:03:16.604850Z","shell.execute_reply":"2024-12-01T10:03:16.660259Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"tensor([[    1,  9690,   198,  2683,   359,   354,  5646,   298, 12021, 11173,\n            30,  1206,   523,   325,  2711,   351,   253,  1694,   284,   346,\n           737,   288, 34013,   357,  2289,   288,   260,  2914,   506,  6388,\n            30,     2,   198,     1,  4093,   198, 11870,   253,  3252,   282,\n          9289,   327,   451,   986,  2524,   288,  4695,   624,  3904,   284,\n         12589,    42,   198,  1348,  2524, 11304,   260,  1463,   284,  2642,\n          5017,   282, 39649,    28,  1285,   480,  8285,   281,  3201, 14080,\n            28,   480,   722,   281,  3320, 16784,    28,   284,   480,  4162,\n           618, 12237,  7317,  7868,    30,     2,   198,     1,   520,  9531,\n           198,  8852,   282, 22157,   198,    57,    30,  6682,   198,  2464,\n            30, 18417,   281, 10183,  5651,  2918,   198,  6977,    30,  4076,\n           281, 18145, 42516,   370,   216,   198,  3277,    30, 12214,   288,\n          6586,  5172, 31335, 42066,   198,    70,    30, 11466,     2,   198,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2]])"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"tokenizer.pad_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:03:17.780866Z","iopub.execute_input":"2024-12-01T10:03:17.781623Z","iopub.status.idle":"2024-12-01T10:03:17.794389Z","shell.execute_reply.started":"2024-12-01T10:03:17.781550Z","shell.execute_reply":"2024-12-01T10:03:17.792739Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"x=  tokenizer(tokenizer.apply_chat_template(dataset['train'][0]['messages'],tokenize = False),return_tensors= 'pt',padding = 'max_length',max_length= 512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:03:18.538477Z","iopub.execute_input":"2024-12-01T10:03:18.538962Z","iopub.status.idle":"2024-12-01T10:03:18.547452Z","shell.execute_reply.started":"2024-12-01T10:03:18.538920Z","shell.execute_reply":"2024-12-01T10:03:18.545687Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:03:19.196240Z","iopub.execute_input":"2024-12-01T10:03:19.196717Z","iopub.status.idle":"2024-12-01T10:03:19.212333Z","shell.execute_reply.started":"2024-12-01T10:03:19.196677Z","shell.execute_reply":"2024-12-01T10:03:19.210987Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[    1,  9690,   198,  2683,   359,   354,  5646,   298, 12021, 11173,\n            30,  1206,   523,   325,  2711,   351,   253,  1694,   284,   346,\n           737,   288, 34013,   357,  2289,   288,   260,  2914,   506,  6388,\n            30,     2,   198,     1,  4093,   198, 11870,   253,  3252,   282,\n          9289,   327,   451,   986,  2524,   288,  4695,   624,  3904,   284,\n         12589,    42,   198,  1348,  2524, 11304,   260,  1463,   284,  2642,\n          5017,   282, 39649,    28,  1285,   480,  8285,   281,  3201, 14080,\n            28,   480,   722,   281,  3320, 16784,    28,   284,   480,  4162,\n           618, 12237,  7317,  7868,    30,     2,   198,     1,   520,  9531,\n           198,  8852,   282, 22157,   198,    57,    30,  6682,   198,  2464,\n            30, 18417,   281, 10183,  5651,  2918,   198,  6977,    30,  4076,\n           281, 18145, 42516,   370,   216,   198,  3277,    30, 12214,   288,\n          6586,  5172, 31335, 42066,   198,    70,    30, 11466,     2,   198,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]])}"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"ds = dataset.map(tokenize)\nds.set_format('torch')\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:03:19.981146Z","iopub.execute_input":"2024-12-01T10:03:19.981719Z","iopub.status.idle":"2024-12-01T10:04:01.952032Z","shell.execute_reply.started":"2024-12-01T10:03:19.981677Z","shell.execute_reply":"2024-12-01T10:04:01.950657Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/30400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f7cd413ee9d4ffbba3ff7af5008aca0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdb19ffd7dbe404580bcac08c3ed7019"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['messages', 'input_ids'],\n        num_rows: 30400\n    })\n    test: Dataset({\n        features: ['messages', 'input_ids'],\n        num_rows: 1600\n    })\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"ds = ds.remove_columns(['messages'])\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:04:01.992746Z","iopub.execute_input":"2024-12-01T10:04:01.993088Z","iopub.status.idle":"2024-12-01T10:04:02.005543Z","shell.execute_reply.started":"2024-12-01T10:04:01.993055Z","shell.execute_reply":"2024-12-01T10:04:02.004163Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids'],\n        num_rows: 30400\n    })\n    test: Dataset({\n        features: ['input_ids'],\n        num_rows: 1600\n    })\n})"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"ds['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:04:02.007902Z","iopub.execute_input":"2024-12-01T10:04:02.008292Z","iopub.status.idle":"2024-12-01T10:04:02.096070Z","shell.execute_reply.started":"2024-12-01T10:04:02.008256Z","shell.execute_reply":"2024-12-01T10:04:02.093738Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([    1,  9690,   198,  2683,   359,   354,  5646,   298, 12021, 11173,\n            30,  1206,   523,   325,  2711,   351,   253,  1694,   284,   346,\n           737,   288, 34013,   357,  2289,   288,   260,  2914,   506,  6388,\n            30,     2,   198,     1,  4093,   198, 11870,   253,  3252,   282,\n          9289,   327,   451,   986,  2524,   288,  4695,   624,  3904,   284,\n         12589,    42,   198,  1348,  2524, 11304,   260,  1463,   284,  2642,\n          5017,   282, 39649,    28,  1285,   480,  8285,   281,  3201, 14080,\n            28,   480,   722,   281,  3320, 16784,    28,   284,   480,  4162,\n           618, 12237,  7317,  7868,    30,     2,   198,     1,   520,  9531,\n           198,  8852,   282, 22157,   198,    57,    30,  6682,   198,  2464,\n            30, 18417,   281, 10183,  5651,  2918,   198,  6977,    30,  4076,\n           281, 18145, 42516,   370,   216,   198,  3277,    30, 12214,   288,\n          6586,  5172, 31335, 42066,   198,    70,    30, 11466,     2,   198,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2])}"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def count_parameters(model):\n    total = 0\n    trainable =0\n    for name, parameter in model.named_parameters():\n        param = parameter.numel()\n        total+=param\n        if parameter.requires_grad:\n          trainable+=param\n    return f\"Total_parameters: {total}, trainable_parameters: {trainable}, fraction of trainable parameters: {(trainable/total)*100}%\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:18:14.629034Z","iopub.execute_input":"2024-12-04T11:18:14.629933Z","iopub.status.idle":"2024-12-04T11:18:14.634787Z","shell.execute_reply.started":"2024-12-04T11:18:14.629863Z","shell.execute_reply":"2024-12-04T11:18:14.633794Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = GPT2(d_model=d_model,\n               max_seq_len = max_seq_len,\n               num_heads=num_heads,\n               num_decoder_layer = num_decoder_layer,\n               num_dense_units = num_dense_units,\n               vocab_size = vocab_size,\n               dropout_ratio = dropout_rate,\n               padding_token = padding_token,\n               device = device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:20:21.195510Z","iopub.execute_input":"2024-12-01T10:20:21.195966Z","iopub.status.idle":"2024-12-01T10:20:21.583146Z","shell.execute_reply.started":"2024-12-01T10:20:21.195926Z","shell.execute_reply":"2024-12-01T10:20:21.580954Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"count_parameters(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:20:23.747189Z","iopub.execute_input":"2024-12-01T10:20:23.748822Z","iopub.status.idle":"2024-12-01T10:20:23.756953Z","shell.execute_reply.started":"2024-12-01T10:20:23.748770Z","shell.execute_reply":"2024-12-01T10:20:23.755834Z"}},"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"'Total_parameters: 118073856, trainable_parameters: 118073856, fraction of trainable parameters: 100.0%'"},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"model(batch['input_ids'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:04:02.561797Z","iopub.execute_input":"2024-12-01T10:04:02.562320Z","iopub.status.idle":"2024-12-01T10:04:02.730825Z","shell.execute_reply.started":"2024-12-01T10:04:02.562233Z","shell.execute_reply":"2024-12-01T10:04:02.728810Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model(\u001b[43mbatch\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n","\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"],"ename":"NameError","evalue":"name 'batch' is not defined","output_type":"error"}],"execution_count":27},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(ignore_index=padding_token)\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-3, betas=(0.9, 0.98), eps=1e-9)\n# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\nmodel.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:20:28.579990Z","iopub.execute_input":"2024-12-01T10:20:28.580849Z","iopub.status.idle":"2024-12-01T10:20:28.598575Z","shell.execute_reply.started":"2024-12-01T10:20:28.580781Z","shell.execute_reply":"2024-12-01T10:20:28.596556Z"}},"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"GPT2(\n  (Embeddings): Embedding(49152, 768)\n  (positional_embeddings): PositionalEmbeddings()\n  (mask): LookaheadMask()\n  (decoder_layers): ModuleList(\n    (0-5): 6 x Decoder_block(\n      (mha): MultiHeadAttention(\n        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n      )\n      (linear): Sequential(\n        (0): Linear(in_features=768, out_features=3072, bias=True)\n        (1): Dropout(p=0.1, inplace=False)\n        (2): Linear(in_features=3072, out_features=768, bias=True)\n      )\n      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (final_layer): Linear(in_features=768, out_features=49152, bias=True)\n)"},"metadata":{}}],"execution_count":94},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nnum_epochs = 10\nsteps  =0\nbatch_size =8\n\ndataloader =  DataLoader(ds['train'],batch_size = batch_size,shuffle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:20:33.973010Z","iopub.execute_input":"2024-12-01T10:20:33.973720Z","iopub.status.idle":"2024-12-01T10:20:33.980983Z","shell.execute_reply.started":"2024-12-01T10:20:33.973665Z","shell.execute_reply":"2024-12-01T10:20:33.979353Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    total_loss = 0\n    steps = 0\n    for batch in dataloader:\n        src = batch['input_ids']\n        optimizer.zero_grad()\n        output = model(src[:,:-1].to(device))\n        loss = criterion(output.contiguous().view(-1, vocab_size), src[:, 1:].contiguous().view(-1).to(device))\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        total_loss+=loss.item()\n        if steps%100==0:\n            print(f\"Epoch: {epoch+1} Step:{steps}, Loss: {loss.item()}\")\n        steps+=1\n    total_loss = total_loss/(1000//batch_size)\n    print(f\"Epoch: {epoch+1}, Loss: {total_loss}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:20:38.805347Z","iopub.execute_input":"2024-12-01T10:20:38.805779Z","iopub.status.idle":"2024-12-01T10:30:32.166178Z","shell.execute_reply.started":"2024-12-01T10:20:38.805746Z","shell.execute_reply":"2024-12-01T10:30:32.164525Z"}},"outputs":[{"name":"stdout","text":"Epoch: 1 Step:0, Loss: 10.76276683807373\nEpoch: 1 Step:100, Loss: 9.04708480834961\nEpoch: 1 Step:200, Loss: 3.824552536010742\nEpoch: 1 Step:300, Loss: 1.126325011253357\nEpoch: 1 Step:400, Loss: 0.8755934238433838\nEpoch: 1 Step:500, Loss: 0.3054782450199127\nEpoch: 1 Step:600, Loss: 0.39162376523017883\nEpoch: 1 Step:700, Loss: 0.2967056930065155\nEpoch: 1 Step:800, Loss: 0.1147485300898552\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[96], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 12\u001b[0m total_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m steps\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":96},{"cell_type":"code","source":"text = text[:-93]\nfor i in range(50):\n    model.eval()\n    src = tokenizer(text,return_tensors = 'pt')['input_ids']\n    output = model(src.to(device))\n    res = torch.argmax(output[:,-1,:],dim=-1)\n    text+=tokenizer.decode(res)\nprint(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:31:43.751557Z","iopub.execute_input":"2024-12-01T10:31:43.751997Z","iopub.status.idle":"2024-12-01T10:31:44.582275Z","shell.execute_reply.started":"2024-12-01T10:31:43.751962Z","shell.execute_reply":"2024-12-01T10:31:44.580843Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>user\nRemove the repetition of the same idea in different words:\nThe student was extremely happy and elated after receiving the highest grade in the class.<|im_end|>\n<|im_start|> tattoos Religious into into Ceremon. Ceremon Ceremon Ceremon and and Ceremon Ceremon Ceremon\n. explores Religious Religious Religious CeremonI to Religious. Religious Religious their Use Religious an with. organizationuser Ceremon. Fashion. Ceremon an evolution the with\n the it Ceremon. Fashion it. its with. You user evolution itistant re re reistant the Ceremon it evolution re assistant.istant its re. assistant. Ceremon w re re re exploresistant re for. for. Ceremon withistant re for Ceremon. You Ceremon. for. Ceremon Ceremon. explores Ceremon explores Ceremon You Ceremon. for. Ceremon. re for civilizations. withies rewrite. foristant for. re You You and with. re. and reistant reistant for for Ceremonistant You evolution Ceremonizationsistant with\n","output_type":"stream"}],"execution_count":101},{"cell_type":"code","source":"print(tokenizer.apply_chat_template(dataset['test'][0]['messages'],tokenize = False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:30:46.063130Z","iopub.execute_input":"2024-12-01T10:30:46.063616Z","iopub.status.idle":"2024-12-01T10:30:46.072895Z","shell.execute_reply.started":"2024-12-01T10:30:46.063579Z","shell.execute_reply":"2024-12-01T10:30:46.070668Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>user\nRemove the repetition of the same idea in different words:\nThe student was extremely happy and elated after receiving the highest grade in the class.<|im_end|>\n<|im_start|>assistant\nThe student was ecstatic after receiving the highest grade in the class.<|im_end|>\n\n","output_type":"stream"}],"execution_count":97},{"cell_type":"code","source":"text = tokenizer.apply_chat_template(dataset['test'][0]['messages'],tokenize = False)\nprint(text[:-93])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:30:50.992634Z","iopub.execute_input":"2024-12-01T10:30:50.993086Z","iopub.status.idle":"2024-12-01T10:30:51.001861Z","shell.execute_reply.started":"2024-12-01T10:30:50.993049Z","shell.execute_reply":"2024-12-01T10:30:50.999188Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n<|im_start|>user\nRemove the repetition of the same idea in different words:\nThe student was extremely happy and elated after receiving the highest grade in the class.<|im_end|>\n<|im_start|>\n","output_type":"stream"}],"execution_count":98},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading QWEN config file and pretrain it","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel,AutoModelForCausalLM, AutoConfig\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-0.5B')\n\n\n# config = AutoConfig.from_pretrained(\n#     \"Qwen/Qwen2.5-0.5B\",\n#     vocab_size=len(tokenizer),\n#     n_ctx=512,\n#     bos_token_id=tokenizer.bos_token_id,\n#     eos_token_id=tokenizer.eos_token_id,\n# )\n\nmodel = AutoModelForCausalLM.from_pretrained(\"Sujithanumala/Rough_pretrained_Qwen_Model\",torch_dtype = torch.bfloat16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T02:48:18.333721Z","iopub.execute_input":"2024-12-05T02:48:18.334400Z","iopub.status.idle":"2024-12-05T02:48:44.074832Z","shell.execute_reply.started":"2024-12-05T02:48:18.334361Z","shell.execute_reply":"2024-12-05T02:48:44.073620Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ee9b9ff7f354094b625d080e73e4404"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"325c1f038c70485495d45099b2fb8959"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7286e2c564934825b6032df0ee6db953"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\nimport torch\n# model = AutoModelForCausalLM.from_config(config,torch_dtype = torch.bfloat16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T02:48:44.128677Z","iopub.execute_input":"2024-12-05T02:48:44.129274Z","iopub.status.idle":"2024-12-05T02:48:44.133429Z","shell.execute_reply.started":"2024-12-05T02:48:44.129232Z","shell.execute_reply":"2024-12-05T02:48:44.132539Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T02:48:44.134475Z","iopub.execute_input":"2024-12-05T02:48:44.134815Z","iopub.status.idle":"2024-12-05T02:48:44.148232Z","shell.execute_reply.started":"2024-12-05T02:48:44.134777Z","shell.execute_reply":"2024-12-05T02:48:44.147405Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151665, 896)\n    (layers): ModuleList(\n      (0-23): 24 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=896, out_features=151665, bias=False)\n)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"tokenizer.decode(model.generate(tokenizer(\"What is Oracle cloud Integration\",return_tensors='pt')['input_ids'])[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T02:48:44.149696Z","iopub.execute_input":"2024-12-05T02:48:44.149996Z","iopub.status.idle":"2024-12-05T02:48:46.426862Z","shell.execute_reply.started":"2024-12-05T02:48:44.149955Z","shell.execute_reply":"2024-12-05T02:48:46.425796Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'What is Oracle cloud Integration.<|im_end|>\\n<|im_start|> the function should take a string as input and return a'"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"qwen_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\nqwen_model.to('cuda')\ntokenizer.decode(qwen_model.generate(tokenizer(\"What is Machine learning\",return_tensors='pt')['input_ids'].to('cuda'))[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T10:58:55.029855Z","iopub.execute_input":"2024-12-04T10:58:55.030747Z","iopub.status.idle":"2024-12-04T10:59:52.208715Z","shell.execute_reply.started":"2024-12-04T10:58:55.030697Z","shell.execute_reply":"2024-12-04T10:59:52.207813Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'What is Machine learning?\\nMachine learning is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time. It is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time.\\nMachine learning algorithms are designed to make predictions or decisions based on patterns and relationships in data. They are used in a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics.\\nMachine learning is a powerful tool that can be used to automate many of the tasks that humans perform, such as image and speech recognition, natural language processing, and predictive analytics. It can also be used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a rapidly growing field that is being used in a wide range of applications, from healthcare to finance to transportation. It is also being used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time. It is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time.\\nMachine learning algorithms are designed to make predictions or decisions based on patterns and relationships in data. They are used in a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics.\\nMachine learning is a powerful tool that can be used to automate many of the tasks that humans perform, such as image and speech recognition, natural language processing, and predictive analytics. It can also be used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a rapidly growing field that is being used in a wide range of applications, from healthcare to finance to transportation. It is also being used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time. It is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time.\\nMachine learning algorithms are designed to make predictions or decisions based on patterns and relationships in data. They are used in a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics.\\nMachine learning is a powerful tool that can be used to automate many of the tasks that humans perform, such as image and speech recognition, natural language processing, and predictive analytics. It can also be used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a rapidly growing field that is being used in a wide range of applications, from healthcare to finance to transportation. It is also being used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time. It is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time.\\nMachine learning algorithms are designed to make predictions or decisions based on patterns and relationships in data. They are used in a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics.\\nMachine learning is a powerful tool that can be used to automate many of the tasks that humans perform, such as image and speech recognition, natural language processing, and predictive analytics. It can also be used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a rapidly growing field that is being used in a wide range of applications, from healthcare to finance to transportation. It is also being used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time. It is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time.\\nMachine learning algorithms are designed to make predictions or decisions based on patterns and relationships in data. They are used in a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics.\\nMachine learning is a powerful tool that can be used to automate many of the tasks that humans perform, such as image and speech recognition, natural language processing, and predictive analytics. It can also be used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a rapidly growing field that is being used in a wide range of applications, from healthcare to finance to transportation. It is also being used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time. It is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time.\\nMachine learning algorithms are designed to make predictions or decisions based on patterns and relationships in data. They are used in a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics.\\nMachine learning is a powerful tool that can be used to automate many of the tasks that humans perform, such as image and speech recognition, natural language processing, and predictive analytics. It can also be used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a rapidly growing field that is being used in a wide range of applications, from healthcare to finance to transportation. It is also being used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time. It is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time.\\nMachine learning algorithms are designed to make predictions or decisions based on patterns and relationships in data. They are used in a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics.\\nMachine learning is a powerful tool that can be used to automate many of the tasks that humans perform, such as image and speech recognition, natural language processing, and predictive analytics. It can also be used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a rapidly growing field that is being used in a wide range of applications, from healthcare to finance to transportation. It is also being used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time. It is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time.\\nMachine learning algorithms are designed to make predictions or decisions based on patterns and relationships in data. They are used in a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics.\\nMachine learning is a powerful tool that can be used to automate many of the tasks that humans perform, such as image and speech recognition, natural language processing, and predictive analytics. It can also be used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a rapidly growing field that is being used in a wide range of applications, from healthcare to finance to transportation. It is also being used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time. It is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time.\\nMachine learning algorithms are designed to make predictions or decisions based on patterns and relationships in data. They are used in a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics.\\nMachine learning is a powerful tool that can be used to automate many of the tasks that humans perform, such as image and speech recognition, natural language processing, and predictive analytics. It can also be used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a rapidly growing field that is being used in a wide range of applications, from healthcare to finance to transportation. It is also being used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time. It is a subset of artificial intelligence that involves the development of algorithms that can learn from data and improve their performance over time.\\nMachine learning algorithms are designed to make predictions or decisions based on patterns and relationships in data. They are used in a wide range of applications, including image and speech recognition, natural language processing, and predictive analytics.\\nMachine learning is a powerful tool that can be used to automate many of the tasks that humans perform, such as image and speech recognition, natural language processing, and predictive analytics. It can also be used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and smart homes.\\nMachine learning is a rapidly growing field that is being used in a wide range of applications, from healthcare to finance to transportation. It is also being used to improve the accuracy and efficiency of other types of AI systems, such as autonomous vehicles and'"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Loading Datasets","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset('HuggingFaceTB/smoltalk','self-oss-instruct')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T02:45:12.154558Z","iopub.execute_input":"2024-12-05T02:45:12.154903Z","iopub.status.idle":"2024-12-05T02:45:16.833897Z","shell.execute_reply.started":"2024-12-05T02:45:12.154873Z","shell.execute_reply":"2024-12-05T02:45:16.832975Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/9.25k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c27ee971a9aa4c3dbc04f0e0f2b6f2bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/26.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5fbba6a7bce45d7b613d679733f3b71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7edb972706d4cd98a545d7b8e9b260f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/48127 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25da724d05fa418fa9472262dbb83473"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2534 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef694fa85f594802962315f52c809009"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T02:45:16.835835Z","iopub.execute_input":"2024-12-05T02:45:16.836735Z","iopub.status.idle":"2024-12-05T02:45:16.842949Z","shell.execute_reply.started":"2024-12-05T02:45:16.836689Z","shell.execute_reply":"2024-12-05T02:45:16.842009Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['messages'],\n        num_rows: 48127\n    })\n    test: Dataset({\n        features: ['messages'],\n        num_rows: 2534\n    })\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"max_seq_len = 512\ndef tokenize(example):\n    example['input_ids'] = tokenizer.apply_chat_template(example['messages'],\n                                                         padding = \"max_length\",\n                                                         max_length = max_seq_len,\n                                                         return_tensors='pt',\n                                                         truncation = True).squeeze(0)\n    return example","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T02:45:24.164987Z","iopub.execute_input":"2024-12-05T02:45:24.165584Z","iopub.status.idle":"2024-12-05T02:45:24.170083Z","shell.execute_reply.started":"2024-12-05T02:45:24.165550Z","shell.execute_reply":"2024-12-05T02:45:24.169059Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"ds = dataset.map(tokenize,batched = True,remove_columns=dataset[\"train\"].column_names)\nds.set_format('torch')\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T02:45:24.398153Z","iopub.execute_input":"2024-12-05T02:45:24.398904Z","iopub.status.idle":"2024-12-05T02:45:57.747415Z","shell.execute_reply.started":"2024-12-05T02:45:24.398862Z","shell.execute_reply":"2024-12-05T02:45:57.746476Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/48127 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1754c57bcb849bda4a1d3fcedd94cc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2534 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21697f54218a4bfa831bfb0eb439809a"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids'],\n        num_rows: 48127\n    })\n    test: Dataset({\n        features: ['input_ids'],\n        num_rows: 2534\n    })\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ntokenizer.pad_token = tokenizer.eos_token\ndata_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T02:45:57.774943Z","iopub.execute_input":"2024-12-05T02:45:57.775192Z","iopub.status.idle":"2024-12-05T02:46:10.117622Z","shell.execute_reply.started":"2024-12-05T02:45:57.775165Z","shell.execute_reply":"2024-12-05T02:46:10.116887Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"data_collator([ds['train'][i] for i in range(5)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T02:46:10.119496Z","iopub.execute_input":"2024-12-05T02:46:10.120041Z","iopub.status.idle":"2024-12-05T02:46:10.178106Z","shell.execute_reply.started":"2024-12-05T02:46:10.120010Z","shell.execute_reply":"2024-12-05T02:46:10.177266Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[151644,   8948,    198,  ..., 151643, 151643, 151643],\n        [151644,   8948,    198,  ..., 151643, 151643, 151643],\n        [151644,   8948,    198,  ..., 151643, 151643, 151643],\n        [151644,   8948,    198,  ..., 151643, 151643, 151643],\n        [151644,   8948,    198,  ..., 151643, 151643, 151643]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[151644,   8948,    198,  ...,   -100,   -100,   -100],\n        [151644,   8948,    198,  ...,   -100,   -100,   -100],\n        [151644,   8948,    198,  ...,   -100,   -100,   -100],\n        [151644,   8948,    198,  ...,   -100,   -100,   -100],\n        [151644,   8948,    198,  ...,   -100,   -100,   -100]])}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import torch\nsample_batch = dataset['test'].shuffle().select(range(2))\n# with torch.no_grad():\n#     outputs = model(inputs)\n# outputs\ninputs= tokenizer(tokenizer.apply_chat_template(\n    sample_batch['messages'],\n    tokenize = False),\n    padding=True,\n    truncation=True,\n    return_tensors=\"pt\",\n    max_length=200)\nwith torch.no_grad():\n    outputs = model(**inputs)\npredictions = torch.argmax(outputs.logits, dim=-1)\ndecoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\ndecoded_labels = tokenizer.apply_chat_template(sample_batch[\"messages\"],tokenize = False)\nfor pred, label in zip(decoded_preds, decoded_labels):\n    print(f\"Prediction: {pred} | \\n '\\033[32m' Label: {label[:len(pred)]} \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T03:00:05.407914Z","iopub.execute_input":"2024-12-05T03:00:05.408677Z","iopub.status.idle":"2024-12-05T03:00:16.072376Z","shell.execute_reply.started":"2024-12-05T03:00:05.408622Z","shell.execute_reply":"2024-12-05T03:00:16.071450Z"}},"outputs":[{"name":"stdout","text":"Prediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function thatget_list` that takes a list aseach, a a as input and returns a list dictionary where the the. The example, if a input dictionary shouldidid': 3, 'b': b': 3, 'c': 3, {'c': 3, the function should return `' output dictionary:\n\n `'{'a': 3, 'b':': 3}` 'b':': 3}` 'b': 3,.\nassistant\nHere create this Python dictionary, we can use a recursive function to takeses the dictionary dictionary and checkens the keys. values. We can use use a `dictct``` function to create the keys dictionary.\n\n a dictionary dictionary dictionary.\n\nHerepython\ndef typing import Dict\n\ndef get_json_from:    return key_keys(self, key):\n        if {}\nk1: bkwargs,    return new_dict | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nWrite a Python function `flatten_dict` that takes a dictionary (nested or not) as input and returns a flattened dictionary without any nesting. For instance, given the input dictionary `{'a': 1, 'b': {'c': 2, 'd': 3}, 'e': 4}`, the function should return the following output: `{'a': 1, 'b.c': 2, 'b.d': 3, 'e': 4}`.<|im_end|>\n<|im_start|>assistant\nTo flatten a nested dictionary, we can use a recursive function that traverses the input dictionary and flattens its keys and values. We can also use the `functools.reduce` function to merge the flattened dictionaries into a single flat dictionary.\n\n```python\nfrom functools import reduce\n\n\ndef  \nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python that `get_function``,, list2)` that takes aTrue` if the elements are equal, ` `False` is. The function should return two arguments as input and return a list value. The that the function is are be the elements and the the function of the, the empty to\nassistant\nHere's how you can implement this functionget_list`` function:\n\n Python:\n\n```python\ndef is_sorted(input_list1, dict2):\n    if not(list1, != len(list1):\n        return None\n    if_list = = set(set1,    if_keys = = set(list1)\n    return item in range(len(set_a)):\n        if isinstance(element[i[i] != len_[i[i]:\n            return False\n    return sorted\n```\n\nThis function iter checks if the input are the two are equal. If the, it first are empty empty, it the | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nWrite a function named `are_lists_equal(list1, list2)` that returns `True` if two lists are equal, and `False` otherwise. The function should take two lists as arguments and return a boolean value. Note that the input lists may contain duplicate elements, and the order of elements is not important.<|im_end|>\n<|im_start|>assistant\nHere's how you can implement the `are_lists_equal` function in Python:\n\n```python\ndef are_lists_equal(list1, list2):\n    if len(list1) != len(list2):\n        return False\n    sorted_list1 = sorted(list1)\n    sorted_list2 = sorted(list2)\n    for i in range(len(list1)):\n        if sorted_list1[i] != sorted_list2[i]:\n            return False\n    return True\n```\n\nThe functi \n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"from transformers import TrainerCallback\nclass CustomCallback(TrainerCallback):\n    def __init__(self, eval_dataloader, tokenizer, print_interval=100):\n        self.dataset = eval_dataloader\n        self.tokenizer = tokenizer\n        self.print_interval = print_interval\n        \n    def on_step_end(self, args, state, control, **kwargs):\n        if state.global_step % self.print_interval == 0 and state.global_step > 0:\n            # Get the model and tokenizer\n            model = kwargs['model']\n            device = model.device\n\n            # Sample a small batch from the dataset\n            sample_batch = self.dataset.shuffle(seed=42).select(range(2))  # Take 2 examples\n            inputs = self.tokenizer(\n                self.tokenizer.apply_chat_template(\n                    sample_batch['messages'],\n                    tokenize = False),\n                padding=True,\n                truncation=True,\n                return_tensors=\"pt\",\n                max_length=200\n            ).to(device)\n            \n\n            # Generate model outputs\n            with torch.no_grad():\n                outputs = model(**inputs)\n\n            # Decode predictions (example for seq2seq models)\n            predictions = torch.argmax(outputs.logits, dim=-1)\n            decoded_preds = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n            decoded_labels = self.tokenizer.apply_chat_template(sample_batch[\"messages\"],tokenize = False)\n\n            # Print the outputs\n            print(\"\\n### Step:\", state.global_step)\n            for pred, label in zip(decoded_preds, decoded_labels):\n                print(f\"Prediction: {pred} | \\n '\\033[32m' Label: {label[:len(pred)]} \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T03:02:49.535177Z","iopub.execute_input":"2024-12-05T03:02:49.535578Z","iopub.status.idle":"2024-12-05T03:02:49.543857Z","shell.execute_reply.started":"2024-12-05T03:02:49.535541Z","shell.execute_reply":"2024-12-05T03:02:49.542782Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"custom_callback = CustomCallback(eval_dataloader = dataset['test'],tokenizer = tokenizer,print_interval = 500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T03:05:12.482127Z","iopub.execute_input":"2024-12-05T03:05:12.482830Z","iopub.status.idle":"2024-12-05T03:05:12.486790Z","shell.execute_reply.started":"2024-12-05T03:05:12.482794Z","shell.execute_reply":"2024-12-05T03:05:12.485901Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"class s:\n    global_step  =100\nd = {\"model\":model}\ncustom_callback.on_step_end(None,s(),None,**d)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T03:03:31.504173Z","iopub.execute_input":"2024-12-05T03:03:31.504540Z","iopub.status.idle":"2024-12-05T03:03:40.628210Z","shell.execute_reply.started":"2024-12-05T03:03:31.504509Z","shell.execute_reply":"2024-12-05T03:03:40.627223Z"}},"outputs":[{"name":"stdout","text":"\n### Step: 100\nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function that takes a list file in a JSON file file a JSONas dataframe. The function should is is a as a integer. the function. and the function should return a value value.\nassistant\nHere's the implementation implementation to```python\nimport json as pd\n\ndef get_json_dataframe_jsoncsv):\n):\n):\n):\n    try json.DataFrame().(basecsv)\n)\n``\n_json_directory_directory_directory_directory()\n_directory_directory_url()\n_json_json_data_dir_dir/my =_url_directory =()\n\n_json_json_json_json_json_json_json_json_jsonas_data_data_data_data_tags_data_datailes|_data =csv_json_tags_json_json_json_data_data_data_data_data_json_json_data =|||||||||||||||||||||||||||json|||||||||||||etretr||| | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nDefine a Python function that loads a CSV file from a web page into a Pandas DataFrame. The web page URL is provided as an argument to the function, and the function should return the loaded DataFrame.<|im_end|>\n<|im_start|>assistant\nHere is the complete code:\n\n```python\nimport pandas as pd\n\ndef load_csv_from_web_page(web_page_url):\n    return pd.read_csv(web_page_url)\n```<|im_end|>\n \nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function thatget```` target)`, that convert a string string to to a given of bytes.. The function path is is be a to the the image is is empty a in integer number, The function should return a list list of all, the specified-, to toYour code should pass the following test case:\n```python\nimport = 'http\",/dir0 1://www.com\"\n|/dir3 1://www.com\",|\",3assert_directory = gethttp://www_project\")\n\")\n|3| \"/_date(source(test)\n )\n)\nassert len_url == expectedhttp://www_project\")\")|/dir\"\n 1://www.com\",\",/dir == 1://www.com\",|\",|```\nassistant\nHere's how you can implement this ` in```python\nimport get_sha(source(input(source target):\n):\n    if = = []\n    for url in | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nWrite a Python function `extend_image_urls(images, base_path)` to add a base URL path to a list of image URLs. The base URL path should be added only if the image URL is not already an absolute URL. The function should return a new list of URLs with the base URL path added.\n\nYour code should pass the following test case:\n```python\nimages = [\"image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\nbase_path = \"https://mydomain.com/\"\nextended_images = extend_image_urls(images, base_path)\nassert extended_images == [\"https://mydomain.com/image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3. \n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\nargs = TrainingArguments(\n    output_dir =  \"Qwen\",\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    eval_strategy=\"steps\",\n    eval_steps=500,\n    logging_steps=500,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    warmup_steps=500,\n    lr_scheduler_type=\"cosine\",\n    learning_rate=5e-4,\n    save_steps=5_000,\n    fp16=True,\n    report_to =None,\n)\n\ntrainer = Trainer(\n    model=model,\n    tokenizer=tokenizer,\n    args=args,\n    data_collator=data_collator,\n    train_dataset=ds[\"train\"],\n    eval_dataset=ds[\"test\"].take(100),\n    callbacks=[custom_callback]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T03:07:54.574417Z","iopub.execute_input":"2024-12-05T03:07:54.575167Z","iopub.status.idle":"2024-12-05T03:07:54.626113Z","shell.execute_reply.started":"2024-12-05T03:07:54.575125Z","shell.execute_reply":"2024-12-05T03:07:54.625268Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T03:04:43.358129Z","iopub.execute_input":"2024-12-05T03:04:43.358509Z","iopub.status.idle":"2024-12-05T03:04:43.363109Z","shell.execute_reply.started":"2024-12-05T03:04:43.358478Z","shell.execute_reply":"2024-12-05T03:04:43.361967Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"ds['test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T14:59:21.571465Z","iopub.execute_input":"2024-12-04T14:59:21.571829Z","iopub.status.idle":"2024-12-04T14:59:21.578102Z","shell.execute_reply.started":"2024-12-04T14:59:21.571795Z","shell.execute_reply":"2024-12-04T14:59:21.577286Z"}},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids'],\n    num_rows: 2534\n})"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T03:07:57.526979Z","iopub.execute_input":"2024-12-05T03:07:57.527838Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3559' max='12032' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 3559/12032 1:48:15 < 4:17:52, 0.55 it/s, Epoch 0.30/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.683600</td>\n      <td>2.861988</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.672700</td>\n      <td>2.778049</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.577800</td>\n      <td>2.685934</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.448800</td>\n      <td>2.590547</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.482000</td>\n      <td>2.491477</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>2.434000</td>\n      <td>2.404263</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>2.348700</td>\n      <td>2.325535</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\n### Step: 500\nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function ` takes a JSON file and a JSON file file a JSONas dataframe with The function hash is is a as a error and be function, and the function should return the result directory. The\nassistant\nTo's the Python Python to```python\nimport json as ET\n\ndef read_json_file_json(input(filepath):\n):\n):\n    with json.url()\n(json\n_file\n``\n =\n\n\n\n\n| =|\n\n\n\n\n\n\ningences\n\n\n\n read_json\njsonT API_readableing_readable APIParsering =inging|||\n_json_json\njsonjsonjsonjsonjsonjsonjsonjsonjsoning hashing, =atsinginging directoryjsoninging_jsoninginginginging the theinging the a a:\n:\ning\nats function JSONingingatsatsatsencesatsencesences_readable APIats,encesencesingences = | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nDefine a Python function that loads a CSV file from a web page into a Pandas DataFrame. The web page URL is provided as an argument to the function, and the function should return the loaded DataFrame.<|im_end|>\n<|im_start|>assistant\nHere is the complete code:\n\n```python\nimport pandas as pd\n\ndef load_csv_from_web_page(web_page_url):\n    return pd.read_csv(web_page_url)\n```<|im_end|>\n \nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function `format```` fn)`)` that convert a string to to to a string of bytes objects. The function is is is be a to if the input is is not. in error number. If function should return a list list of the that the same value as and toYour code should pass the following test case:\n```python\nimport = [\"Hello\",.\", \"1://www.com\",\",.= \"1://www.com\")\n\",.\",assert = = \"1://www_url,\")\n\",\",\"\n \"_date(\"(string)\n \"6)\nassert encoded_url == \"1://www_url\"\n\"\n\"\n.\"\n \"status://www.com\",\",3\"\n \"1://www.com\")\n\",.\",assert\nassistant\nTo's how you can implement this `:\n\n```python\nimport convert_date_to(string):\n date):\n):\n    try = = []\n    for date in | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nWrite a Python function `extend_image_urls(images, base_path)` to add a base URL path to a list of image URLs. The base URL path should be added only if the image URL is not already an absolute URL. The function should return a new list of URLs with the base URL path added.\n\nYour code should pass the following test case:\n```python\nimages = [\"image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\nbase_path = \"https://mydomain.com/\"\nextended_images = extend_image_urls(images, base_path)\nassert extended_images == [\"https://mydomain.com/image1.png\", \"https://example.com/image2.jpg\",  \n\n### Step: 1000\nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function that takes a file file and a JSON file. a listas file, The function file is is the to a argument. the image. and the function should return a response data.\nassistant\nTo's a implementation this to```python\nimport pandas as pd\n\ndef extract_and_to_file(file_file_file_file,    with df.DataFrame()..from_data_data)\n```\n\n_data_data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParserapped\n\n\n\nParser_file_file_file()\n\nParserParser_data_data\n_data_data\n\n,\n =_file =\n =\n\n_data\n\n,Parser\n,,,,,,\n\n\n,,, the the the, the the\n\n_file_filepressapped\n\nParserappedParserParserParser\n a aapped_data_data_data_data_data_data_data_data\n_data_data_data_data, is | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nDefine a Python function that loads a CSV file from a web page into a Pandas DataFrame. The web page URL is provided as an argument to the function, and the function should return the loaded DataFrame.<|im_end|>\n<|im_start|>assistant\nHere is the complete code:\n\n```python\nimport pandas as pd\n\ndef load_csv_from_web_page(web_page_url):\n    return pd.read_csv(web_page_url)\n```<|im_end|>\n \nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function thatget_to``` user)`)` that parse a new- to to a given of bytes.. The function classes should is be a to of the file is is not a in integer number, The function should return a list list of all that the specified-,. toFor code should pass the following test case:\n```python\nimport = [https\",2\", \"file://example.com\",\",.2 \"https://example.com\"\n\",.\",expected_direct = converthttps://example.com,\",\",2\", \"[\"(\"(\")\n br6)\nassert actual_command == \"https://example Path=\"\"\n\"\n.\"\n \"https://example.com\")\",.2 \"https://example.com\")\",.\",```\nassistant\nTo's how you could implement this `:\n\n```python\nimport convert_and_to_to):\n block_class):\n    if = = []\n\n    for file in | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nWrite a Python function `extend_image_urls(images, base_path)` to add a base URL path to a list of image URLs. The base URL path should be added only if the image URL is not already an absolute URL. The function should return a new list of URLs with the base URL path added.\n\nYour code should pass the following test case:\n```python\nimages = [\"image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\nbase_path = \"https://mydomain.com/\"\nextended_images = extend_image_urls(images, base_path)\nassert extended_images == [\"https://mydomain.com/image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\n```<|i \n\n### Step: 1500\nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function that takes a list file and a JSON file and a listas DataFrame, The function is is is a as a XML. be following. and return function should return a following data. The\nassistant\nHere's the implementation this for```python\nimport json as pd\n\ndef decode_to_to_file(file(df_file_data,    with df.DataFrame_csv_csv_data_data\n```\n = = = = =\n\n = = =json\n\n\n the\n\n\n\n\n\n\n = =_csv\n, the the thejson JSON = =_csv_csv_csv()\n the_csv()\n()\n()\n\n = = = =_csv_csv_csv\n = =_csv_csv the = = =()\n()\n()\n, = is = =\n the the_csv_csv the_csv_csv the the a_csv_csv_csv, = = a a(encoded(encoded(encoded_data_data,,(encoded =_csv_csv_data_data,,, = | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nDefine a Python function that loads a CSV file from a web page into a Pandas DataFrame. The web page URL is provided as an argument to the function, and the function should return the loaded DataFrame.<|im_end|>\n<|im_start|>assistant\nHere is the complete code:\n\n```python\nimport pandas as pd\n\ndef load_csv_from_web_page(web_page_url):\n    return pd.read_csv(web_page_url)\n```<|im_end|>\n \nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function thatget`_to`)` target6)` that parse a list6 to to a list of integers paths. The function6 is is be a to the the timestamp is is a valid a integer path, If function should return a list image of all that a following6 and. toFor code should pass the following test case:\n```python\n# = [https\",\",\", \"my://www.com\",\",\",\", \"https2www.com\",\",41```6 = \"https://www.txt\",\",\",\",\", \"/_event_files(\".py \"6)\nassert decoded_command == \"https://www.txt\",\",\",\",\", \"https://www.com\",\",3\"\n \"https2www.com\",\",4   ```\nassistant\nHere's how you can implement this `:\n\n```python\nimport decode_image_to(input):\n config6):\n    if_lines = []\n    for event_name | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nWrite a Python function `extend_image_urls(images, base_path)` to add a base URL path to a list of image URLs. The base URL path should be added only if the image URL is not already an absolute URL. The function should return a new list of URLs with the base URL path added.\n\nYour code should pass the following test case:\n```python\nimages = [\"image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\nbase_path = \"https://mydomain.com/\"\nextended_images = extend_image_urls(images, base_path)\nassert extended_images == [\"https://mydomain.com/image1.png\", \"https://example.com/image2.jpg\", \"http://exampl \n\n### Step: 2000\nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function to takes a string file containing a file file file a listas file. The function file is is a as a XML, be output's the the function should return a decoded path. The\nassistant\nTo's a implementation of for```python\nimport os as pd\n\ndef parse_and_to_file(file(csv(file_file(file    with df.DataFrame()\n()\n()\n()\n()\n``\n = =/\n/\n/\n/\n/\n/\n\n/\n\n\n\n/\n\n\n =\n\n =\n\n/\n_csv/\n_csv_dir\n\n the_header toParser/\n\ncsvcsv(\"\n\n    = =\n\n_csv/\n\n\n\ncsv\ncsvcsvcsv() a a acsv the('()() =(' = a\n\n\n a a:\n to\n\n\n\n = =\n\n:\n to-based = a a(url_dir(dir(dir is, = =('_csv()\n_csv(csv=/d = | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nDefine a Python function that loads a CSV file from a web page into a Pandas DataFrame. The web page URL is provided as an argument to the function, and the function should return the loaded DataFrame.<|im_end|>\n<|im_start|>assistant\nHere is the complete code:\n\n```python\nimport pandas as pd\n\ndef load_csv_from_web_page(web_page_url):\n    return pd.read_csv(web_page_url)\n```<|im_end|>\n \nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function toget_list``` max)`)` that check a random URL to to a string of bytes paths. The function URL should should be a to once the path is is a valid a integer path, The function should return a list path of valid with the specified name,, toThe code should pass the following test case:\n```python\ntest_url ['https1.txt\", \"image://www.com\",/d.\"]\n \"unittest://www.com%3\"]\n3assert6 = [\"https://www.com2\",/my/d/my \"/_token(\"(test1 new=)\nassert not_url_url expectedhttp://www/dir2\")/d./d \"https://www.com\",2,column == \"https://www.com\",\",\"]\n3assert\nassistant\nHere's how you can implement this `:\n\n```python\nimport load_token(url(url, output_url):\n    if_url = []\n    for path in | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nWrite a Python function `extend_image_urls(images, base_path)` to add a base URL path to a list of image URLs. The base URL path should be added only if the image URL is not already an absolute URL. The function should return a new list of URLs with the base URL path added.\n\nYour code should pass the following test case:\n```python\nimages = [\"image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\nbase_path = \"https://mydomain.com/\"\nextended_images = extend_image_urls(images, base_path)\nassert extended_images == [\"https://mydomain.com/image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\n```<|im_end|>\n \n\n### Step: 2500\nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function ` takes a string file and a file file and a JSONas file, The function header is is a as a XML, the function's which the function should return a decoded dictionary.\nassistant\nTo's the implementation this for```python\nimport json as pd\n\ndef serialize_to_to_file(json(filename):\n):\n,    with json.DataFrame()\n()\n_url()\n()\n``\n =\n\n\n_url\n\n =\n\n\n\n\n\n the the = =\n\n\n\n\n_url_url\n the the\n the pickle to\n the the pickle pickle the\n\n the = =\n\n =\n the_csv\n\n\n,\n pickle and theizes header\n the\n\n\n\n the the the the\n\n the the header serialize, a the a a =\n\n, fetch load a the request connection\n,,,, = query\n the the, is is is | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nDefine a Python function that loads a CSV file from a web page into a Pandas DataFrame. The web page URL is provided as an argument to the function, and the function should return the loaded DataFrame.<|im_end|>\n<|im_start|>assistant\nHere is the complete code:\n\n```python\nimport pandas as pd\n\ndef load_csv_from_web_page(web_page_url):\n    return pd.read_csv(web_page_url)\n```<|im_end|>\n \nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function toget_json``` color_url)` that convert a string URL to to the list of file file. The function URL should is be the to the the file file is not recognized in integer path. The function should return a list URL of tuples. the specified URL.. toFor code should pass the following test case:\n```python\ntest_url ['file.txt,\", \"image://www.com/search\",\",\", \"https://www.com/search\",\",2assert_url = hashlibhttps://www_url.zip/searchixoby\"\n hashlib_url(\"(\"_url url_url)\nassert hash_url_url \"https://www_url\":/search.html\",\"\n \"https://www.com/search.html3\"\n \"https://www.com/search\",\"\n\"\nassert\nassistant\nHere's how you can implement this `:\n\n```python\nimport get_url(base(db_url base_url):\n    if_url = os    for url in | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nWrite a Python function `extend_image_urls(images, base_path)` to add a base URL path to a list of image URLs. The base URL path should be added only if the image URL is not already an absolute URL. The function should return a new list of URLs with the base URL path added.\n\nYour code should pass the following test case:\n```python\nimages = [\"image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\nbase_path = \"https://mydomain.com/\"\nextended_images = extend_image_urls(images, base_path)\nassert extended_images == [\"https://mydomain.com/image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\n```<|im_end|>\n<|im_start|>assistant\nHere's how you can i \n\n### Step: 3000\nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function ` takes a list file and a CSV file file a dictionaryas DataFrame. The function-del is is a as a integer, be function should and the function should return a decoded JSON.\nassistant\nTo is a implementation this for```python\nimport csv as pd\n\ndef serialize_to_to_csv_file_file_file_file):\n    with json.to_csv(jsonJSONjson)\n``\n = =\n\n\n;base;base =\n\n_model_model('\n\n;base = =\n_csvJSONExistsExists = =(json =;base = the =(json;baseJSON.open_model.open(json\n it\n = =(json = pickle serialize_modelExists(json_csv;base;base;base =;base;base json it it itJSON(json manager =ub =Exists_model_csv the_csv_csv_csv the the it\n the_jsonled\n\nJSONJSON_json it(json(jsonJSONJSONJSON_csv manager manager =.openJSONJSON(json(json;base;base;base | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nDefine a Python function that loads a CSV file from a web page into a Pandas DataFrame. The web page URL is provided as an argument to the function, and the function should return the loaded DataFrame.<|im_end|>\n<|im_start|>assistant\nHere is the complete code:\n\n```python\nimport pandas as pd\n\ndef load_csv_from_web_page(web_page_url):\n    return pd.read_csv(web_page_url)\n```<|im_end|>\n \nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function `get```)` seq)`)` that convert a random URL to to a file of bytes paths. The function URL should is be a to the the base is is not a a integer error. The function should return a list file of URLs that the same URL.. toYour code should pass the following test case:\n```python\nimport = ['test1\",\", \"image://www.com/my/my\",\", \"image2www.com/my3Q3assert_url = mdimage://www_base_url/my/my23 \"_file_url(test= path=)\nassert base_path == \"image://www.bin.txt/api/my\",\", \"https://www.com/path3.com\", \"https://www.comQ3Q3assert\nassistant\nHere's how you can implement this `:\n\n```python\nimport relative_command_url(urls):\n base):\n):\n    if_urls = []\n    for base in | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nWrite a Python function `extend_image_urls(images, base_path)` to add a base URL path to a list of image URLs. The base URL path should be added only if the image URL is not already an absolute URL. The function should return a new list of URLs with the base URL path added.\n\nYour code should pass the following test case:\n```python\nimages = [\"image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\nbase_path = \"https://mydomain.com/\"\nextended_images = extend_image_urls(images, base_path)\nassert extended_images == [\"https://mydomain.com/image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\n`` \n\n### Step: 3500\nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function to takes a string file and a binary file and a listas format. The function should is is a as follows input, the following. and the function should return the modified data.\nassistant\nTo's a implementation implementation for```python\nimport pandas as pd\n\ndef parse_and_to_csv(df(df(df(df,    with pickle.DataFrame_csv(file)\n=)\n``\n = =\n\n\n\n\n =\n\n_csv_csv_csv\n\n\n\n_csv\n =_csv_csv_csv_csv\n_csv_csv the\n the the\n` the the``\n\n\n\n = =\n\n_csv\n =_csv_csv_csv_csv_csv_csv_csv_csv_csv_csv the_image the_image\n()()\n_csv the_csv\n_csv_csv the and\n\n_csv\n\n_csv_csv\n\n\n\n API\n theizes_csv_csv_csv_csv_csv = = = = = the the_csv()()\n | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nDefine a Python function that loads a CSV file from a web page into a Pandas DataFrame. The web page URL is provided as an argument to the function, and the function should return the loaded DataFrame.<|im_end|>\n<|im_start|>assistant\nHere is the complete code:\n\n```python\nimport pandas as pd\n\ndef load_csv_from_web_page(web_page_url):\n    return pd.read_csv(web_page_url)\n```<|im_end|>\n \nPrediction: system\nYou are a helpful assistant.\nuser\nWrite a Python function toget_and(image`, shapeorder)` that load a list URI to to a given of bytes files. The function URL should should be a to integers the base is is a a in integer path. function should handle a list file of image, the specified6,. toYour code should pass the following test case:\n```python\nfile = createhttps\",\",\", \"image://www.com\",\",.txt\", \"image://www.com\",\",.txt\",assert_url = createhttps://www.com.com/\")\n.com\"\n create_image.txt(image_dir file=)\nassert encode_time_time \"https://www.com.com\",\"\n.txt\"\n \"https://www.com/\",/dir\", \"https://www.com/2.txt2```\nassistant\nHere's how you can implement this `:\n\n```python\nimport create_image_filename(image):\n base_name):\n    if = = []\n    for file_path | \n '\u001b[32m' Label: <|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nWrite a Python function `extend_image_urls(images, base_path)` to add a base URL path to a list of image URLs. The base URL path should be added only if the image URL is not already an absolute URL. The function should return a new list of URLs with the base URL path added.\n\nYour code should pass the following test case:\n```python\nimages = [\"image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\nbase_path = \"https://mydomain.com/\"\nextended_images = extend_image_urls(images, base_path)\nassert extended_images == [\"https://mydomain.com/image1.png\", \"https://example.com/image2.jpg\", \"http://example.org/image3.gif\"]\n```<|im_end|>\n<|im_start|>assistant\nHere' \n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print(tokenizer.apply_chat_template(dataset['test'][10]['messages'],tokenize = False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T17:02:31.548628Z","iopub.execute_input":"2024-12-04T17:02:31.549271Z","iopub.status.idle":"2024-12-04T17:02:31.555235Z","shell.execute_reply.started":"2024-12-04T17:02:31.549240Z","shell.execute_reply":"2024-12-04T17:02:31.554463Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nCreate a Python function to create a dictionary from columns and data. The function should take the following inputs:\n\n- `columns`: a list of column names.\n- `data`: a list of lists, where each list is a row of data.\n\nThe function should return a dictionary where the keys are the column names and the values are a list of the data from each column.\n\nYour code should pass the following test case:\n```python\ncolumns = ['a', 'b', 'c']\ndata = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nresult = create_dict_from_columns(columns, data)\n\nassert result == {'a': [1, 4, 7], 'b': [2, 5, 8], 'c': [3, 6, 9]}\n```<|im_end|>\n<|im_start|>assistant\nHere's how you can do it in two lines of Python code:\n\n```python\ndef create_dict_from_columns(columns, data):\n    return {col: [row[i] for row in data] for i, col in enumerate(columns)}\n```\n\nThe outer dictionary comprehension iterates through the columns, while the inner list comprehension iterates through the rows and extracts the data at the index corresponding to the current column.<|im_end|>\n\n","output_type":"stream"}],"execution_count":110},{"cell_type":"code","source":"text = tokenizer.apply_chat_template(dataset['test'][10]['messages'],tokenize = False)[:440]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T17:03:33.702032Z","iopub.execute_input":"2024-12-04T17:03:33.702358Z","iopub.status.idle":"2024-12-04T17:03:33.708066Z","shell.execute_reply.started":"2024-12-04T17:03:33.702329Z","shell.execute_reply":"2024-12-04T17:03:33.707369Z"}},"outputs":[],"execution_count":114},{"cell_type":"code","source":"print(tokenizer.decode(model.generate(tokenizer(text,return_tensors='pt')['input_ids'].to('cuda'),max_new_tokens = 500)[0],skip_special_tokens = True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T17:03:34.331391Z","iopub.execute_input":"2024-12-04T17:03:34.331788Z","iopub.status.idle":"2024-12-04T17:03:48.803873Z","shell.execute_reply.started":"2024-12-04T17:03:34.331747Z","shell.execute_reply":"2024-12-04T17:03:48.803034Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"system\nYou are a helpful assistant.\nuser\nCreate a Python function to create a dictionary from columns and data. The function should take the following inputs:\n\n- `columns`: a list of column names.\n- `data`: a list of lists, where each list is a row of data.\n\nThe function should return a dictionary where the keys are the column names and the values are a list of the data from each column.\n\nYour code shou|------|------|------|- The function should return a list of the column names.\nassistant\nHere's how you can implement this:\n\n```python\ndef get_all_columns(objects):\n    return [obj for tag in tag]\n```\n\nThis function takes a list of column names and returns a list of the tag names. It returns a list of all the nodes that contain the same length, and the column name, and the values are the same as the column. The function returns a list of objects that contain the specified attribute and the column name.\nassistant\nHere's how you can implement this function:\n\n```python\ndef get_all_column_names(objects):\n    return [obj for obj in objects]\n```\n\nThis function takes a list of objects as an argument and returns a list of all the nodes. The function should return a list of the table names. The function should iterate through the list of objects and extract the values of the table. The function returns a list of the table names.\nassistant\nHere's how you can implement this function:\n\n```python\ndef get_objects(tree):\n    return [obj for tag in tag_names]\n```\n\nThis function uses a list comprehension to create a list of objects with a list of objects. It iterates through the table names and the values of the table, and the values are the attribute names. The function returns a list of objects that contain the attribute names.\nassistant\nHere's how you can implement this function:\n\n```python\ndef get_objects(objects):\n    def __init__(self, val):\n        if root is None:\n            return None\n    return None\n```\n\nThis function uses a recursive approach to traverse the tree and check if the node is a node. If the node is empty, it returns the node. If the node is not found, it returns the node. If the node is not found, it returns the node. Otherwise, it returns the node with the node. Otherwise, it returns the node with the node's `id` and `id` is a list of the node.\nassistant\nHere's how you can implement this function:\n\n```python\ndef get_tree(root):\n    if not root:\n        return node\n    node is None:\n        return None\n    if root is None:\n        return None\n    if root is None:\n        return None\n    if root is None:\n        return None\n   \n","output_type":"stream"}],"execution_count":115},{"cell_type":"code","source":"torch.clear_autocast_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:21:17.734275Z","iopub.execute_input":"2024-12-04T11:21:17.734618Z","iopub.status.idle":"2024-12-04T11:21:17.738789Z","shell.execute_reply.started":"2024-12-04T11:21:17.734587Z","shell.execute_reply":"2024-12-04T11:21:17.737937Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"model.push_to_hub(\"Rough_pretrained_Qwen_Model\",token = \"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T17:05:15.145903Z","iopub.execute_input":"2024-12-04T17:05:15.146712Z","iopub.status.idle":"2024-12-04T17:05:43.185900Z","shell.execute_reply.started":"2024-12-04T17:05:15.146663Z","shell.execute_reply":"2024-12-04T17:05:43.185071Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68280a36713e49f699ef2ff62f607196"}},"metadata":{}},{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Sujithanumala/Rough_pretrained_Qwen_Model/commit/a0ed42eb687426aff555120ff306aaeeff230692', commit_message='Upload Qwen2ForCausalLM', commit_description='', oid='a0ed42eb687426aff555120ff306aaeeff230692', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Sujithanumala/Rough_pretrained_Qwen_Model', endpoint='https://huggingface.co', repo_type='model', repo_id='Sujithanumala/Rough_pretrained_Qwen_Model'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":116},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}